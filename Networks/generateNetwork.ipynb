{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from NeuralNetwork import  NeuralNetwork\n",
    "import numpy as np\n",
    "import onnx, onnx.numpy_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([10])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weightName = \"mnist_relu_5_100.onnx\"\n",
    "model = onnx.load(weightName)\n",
    "bs = []\n",
    "Ws = []\n",
    "\n",
    "for data in model.graph.initializer:\n",
    "    if \"bias\" in data.name:\n",
    "        bs.append(torch.from_numpy(onnx.numpy_helper.to_array(data)).float())\n",
    "        print(bs[-1].shape)\n",
    "    else:\n",
    "        Ws.append(torch.from_numpy(onnx.numpy_helper.to_array(data)).float())\n",
    "dimensions = [Ws[0].shape[1]]\n",
    "for i in range(len(Ws)):\n",
    "    dimensions.append(Ws[i].shape[0])\n",
    "layers = []\n",
    "for i in range(len(dimensions) - 1):\n",
    "    layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "    if i < len(dimensions) - 2:\n",
    "        layers.append(nn.ReLU())\n",
    "network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"randomNetwork.pth\")\n",
    "\n",
    "count = 0\n",
    "for name, param in network.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        param.data = Ws[count]\n",
    "    if \"bias\" in name:\n",
    "        param.data = bs[count]\n",
    "        count += 1\n",
    "\n",
    "networkClass.Linear = network\n",
    "# torch.save(networkClass.state_dict(), \"mnist_5_100.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "for w in Ws:\n",
    "    print(w.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(60, 100)\n",
      "(20, 60)\n",
      "(2, 20)\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(\"binaryClassificationData30.pt\")\n",
    "for w in data['ws']:\n",
    "    print(w.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "dimensions = [784, 50, 50, 50, 50, 50, 10]\n",
    "layers = []\n",
    "for i in range(len(dimensions) - 1):\n",
    "    layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "    if i < len(dimensions) - 2:\n",
    "        layers.append(nn.ReLU())\n",
    "network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"randomNetwork.pth\")\n",
    "\n",
    "# count = 0\n",
    "# for name, param in network.named_parameters():\n",
    "#     if \"weight\" in name:\n",
    "#         param.data = torch.from_numpy(data['ws'][count])\n",
    "#     if \"bias\" in name:\n",
    "#         param.data = torch.from_numpy(data['bs'][count].squeeze())\n",
    "#         count += 1\n",
    "\n",
    "networkClass.Linear = network\n",
    "torch.save(networkClass.state_dict(), \"randomNetwork3.pth\")\n",
    "# torch.save(networkClass.state_dict(), \"trainedNetwork1.pth\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282.87342975542913\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "result = 1\n",
    "for w in data['ws']:\n",
    "    result *= np.linalg.norm(w, ord=float(\"inf\"))\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(60, 100)\n",
      "(20, 60)\n",
      "(2, 20)\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}