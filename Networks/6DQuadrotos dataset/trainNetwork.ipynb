{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NetworkModels.NeuralNetwork import NeuralNetwork\n",
    "torch.set_printoptions(precision=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainCompleteLoop = False\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "fileName = \"fourDimTrainData.mat\"\n",
    "# data = loadmat(fileName)\n",
    "# XFull = data['X']\n",
    "# YFull = data['y']\n",
    "data = loadmat(fileName)\n",
    "XFull = data['Xtrain']\n",
    "YFull = data['Ytrain']\n",
    "A = data['A']\n",
    "B = data['B']\n",
    "if XFull.shape[0] < XFull.shape[1]:\n",
    "    XFull = XFull.T\n",
    "    YFull = YFull.T\n",
    "if \"quad\" in fileName:\n",
    "    A = np.zeros((6, 6), dtype=np.float32)\n",
    "    A[0, 3] = 1.\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3), dtype=np.float32)\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1), dtype=np.float32)\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "    lastDim = 3\n",
    "elif \"doubleIntegrator\" in fileName:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "    lastDim = 1\n",
    "elif \"fourDim\" in fileName:\n",
    "    pass\n",
    "    lastDim = 2\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "if trainCompleteLoop:\n",
    "    YFull = (A @ XFull.T + B @ YFull.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "dataSplit = 0.9\n",
    "trainSize = int(dataSplit * XFull.shape[0])\n",
    "\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, lastDim),)\n",
    "\n",
    "# net = nn.Sequential(\n",
    "#     nn.Linear(6, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, lastDim))\n",
    "numberOfLayers = (len(net) + 1) // 2\n",
    "net.to(device)\n",
    "train_batch_size = 64\n",
    "\n",
    "def my_loss(output, target):\n",
    "    prod = torch.linalg.norm(net[0].weight)\n",
    "    for i in range(1, numberOfLayers):\n",
    "        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "    loss = torch.mean((output - target)**2) + gamma * prod\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(4316, 2)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YFull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "checkpointResume = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 gamma 0.0 lambda: 3.98799991607666\n",
      "MSE loss:  0.09762915223836899 , Norm of product: tensor(10.19286919, device='cuda:0')\n",
      "epoch: 0 gamma 0.0 lambda: 3.98799991607666\n",
      "validation losses average:  tensor(0.09918432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 10 gamma 0.0 lambda: 3.8699615001678467\n",
      "MSE loss:  6.489016959676519e-05 , Norm of product: tensor(12.38774872, device='cuda:0')\n",
      "epoch: 10 gamma 0.0 lambda: 3.8699615001678467\n",
      "validation losses average:  tensor(6.79051373e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 20 gamma 0.0 lambda: 3.7554163932800293\n",
      "MSE loss:  2.441372453176882e-05 , Norm of product: tensor(12.39990902, device='cuda:0')\n",
      "epoch: 20 gamma 0.0 lambda: 3.7554163932800293\n",
      "validation losses average:  tensor(2.01377406e-05, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 30 gamma 0.0 lambda: 3.6442620754241943\n",
      "MSE loss:  8.510520274285227e-06 , Norm of product: tensor(12.38513565, device='cuda:0')\n",
      "epoch: 30 gamma 0.0 lambda: 3.6442620754241943\n",
      "validation losses average:  tensor(9.05192610e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 40 gamma 0.0 lambda: 3.536397695541382\n",
      "MSE loss:  6.999379365879577e-06 , Norm of product: tensor(12.28776550, device='cuda:0')\n",
      "epoch: 40 gamma 0.0 lambda: 3.536397695541382\n",
      "validation losses average:  tensor(5.56248597e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 50 gamma 0.0 lambda: 3.4317262172698975\n",
      "MSE loss:  6.307743660727283e-06 , Norm of product: tensor(12.20216751, device='cuda:0')\n",
      "epoch: 50 gamma 0.0 lambda: 3.4317262172698975\n",
      "validation losses average:  tensor(4.03029026e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 60 gamma 0.0 lambda: 3.3301522731781006\n",
      "MSE loss:  2.9678558348678052e-06 , Norm of product: tensor(12.15472317, device='cuda:0')\n",
      "epoch: 60 gamma 0.0 lambda: 3.3301522731781006\n",
      "validation losses average:  tensor(3.16667933e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 70 gamma 0.0 lambda: 3.2315850257873535\n",
      "MSE loss:  3.453239287409815e-06 , Norm of product: tensor(12.13161469, device='cuda:0')\n",
      "epoch: 70 gamma 0.0 lambda: 3.2315850257873535\n",
      "validation losses average:  tensor(2.77095523e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 80 gamma 0.0 lambda: 3.1359353065490723\n",
      "MSE loss:  1.2477054269766086e-06 , Norm of product: tensor(12.11638546, device='cuda:0')\n",
      "epoch: 80 gamma 0.0 lambda: 3.1359353065490723\n",
      "validation losses average:  tensor(2.14222950e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 90 gamma 0.0 lambda: 3.043116807937622\n",
      "MSE loss:  2.2567726318811765e-06 , Norm of product: tensor(12.09666634, device='cuda:0')\n",
      "epoch: 90 gamma 0.0 lambda: 3.043116807937622\n",
      "validation losses average:  tensor(1.76307208e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 100 gamma 0.0 lambda: 2.953045129776001\n",
      "MSE loss:  2.330412144146976e-06 , Norm of product: tensor(12.06885052, device='cuda:0')\n",
      "epoch: 100 gamma 0.0 lambda: 2.953045129776001\n",
      "validation losses average:  tensor(1.43782654e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 110 gamma 0.0 lambda: 2.8656394481658936\n",
      "MSE loss:  1.0438944855195587e-06 , Norm of product: tensor(12.02907467, device='cuda:0')\n",
      "epoch: 110 gamma 0.0 lambda: 2.8656394481658936\n",
      "validation losses average:  tensor(1.19869355e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 120 gamma 0.0 lambda: 2.7808210849761963\n",
      "MSE loss:  2.2970043573877774e-06 , Norm of product: tensor(11.97746181, device='cuda:0')\n",
      "epoch: 120 gamma 0.0 lambda: 2.7808210849761963\n",
      "validation losses average:  tensor(1.10396604e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 130 gamma 0.0 lambda: 2.6985132694244385\n",
      "MSE loss:  7.75999410507211e-07 , Norm of product: tensor(11.92728043, device='cuda:0')\n",
      "epoch: 130 gamma 0.0 lambda: 2.6985132694244385\n",
      "validation losses average:  tensor(1.11798897e-06, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 140 gamma 0.0 lambda: 2.6186411380767822\n",
      "MSE loss:  7.507173904741649e-07 , Norm of product: tensor(11.87731552, device='cuda:0')\n",
      "epoch: 140 gamma 0.0 lambda: 2.6186411380767822\n",
      "validation losses average:  tensor(8.47681690e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 150 gamma 0.0 lambda: 2.541133165359497\n",
      "MSE loss:  6.790208431084466e-07 , Norm of product: tensor(11.82483196, device='cuda:0')\n",
      "epoch: 150 gamma 0.0 lambda: 2.541133165359497\n",
      "validation losses average:  tensor(7.91813704e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 160 gamma 0.0 lambda: 2.4659194946289062\n",
      "MSE loss:  7.71911516039836e-07 , Norm of product: tensor(11.76690197, device='cuda:0')\n",
      "epoch: 160 gamma 0.0 lambda: 2.4659194946289062\n",
      "validation losses average:  tensor(6.31947501e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 170 gamma 0.0 lambda: 2.3929319381713867\n",
      "MSE loss:  5.244585850050498e-07 , Norm of product: tensor(11.71899033, device='cuda:0')\n",
      "epoch: 170 gamma 0.0 lambda: 2.3929319381713867\n",
      "validation losses average:  tensor(5.91138473e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 180 gamma 0.0 lambda: 2.3221049308776855\n",
      "MSE loss:  6.794748514948878e-07 , Norm of product: tensor(11.67574501, device='cuda:0')\n",
      "epoch: 180 gamma 0.0 lambda: 2.3221049308776855\n",
      "validation losses average:  tensor(4.93090909e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 190 gamma 0.0 lambda: 2.2533743381500244\n",
      "MSE loss:  3.1944227885105647e-07 , Norm of product: tensor(11.64697647, device='cuda:0')\n",
      "epoch: 190 gamma 0.0 lambda: 2.2533743381500244\n",
      "validation losses average:  tensor(4.43425478e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 200 gamma 0.0 lambda: 2.186678171157837\n",
      "MSE loss:  2.6353524162914255e-07 , Norm of product: tensor(11.62503815, device='cuda:0')\n",
      "epoch: 200 gamma 0.0 lambda: 2.186678171157837\n",
      "validation losses average:  tensor(4.21963023e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 210 gamma 0.0 lambda: 2.1219561100006104\n",
      "MSE loss:  5.111664904688951e-07 , Norm of product: tensor(11.61146450, device='cuda:0')\n",
      "epoch: 210 gamma 0.0 lambda: 2.1219561100006104\n",
      "validation losses average:  tensor(3.43281357e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 220 gamma 0.0 lambda: 2.0591495037078857\n",
      "MSE loss:  2.6240843453706475e-07 , Norm of product: tensor(11.60327721, device='cuda:0')\n",
      "epoch: 220 gamma 0.0 lambda: 2.0591495037078857\n",
      "validation losses average:  tensor(3.34497940e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 230 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  2.867050739041588e-07 , Norm of product: tensor(11.59964371, device='cuda:0')\n",
      "epoch: 230 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(2.69813427e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 240 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  1.1472587857497274e-07 , Norm of product: tensor(11.58942413, device='cuda:0')\n",
      "epoch: 240 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(2.19934734e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 250 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  2.51301173648244e-07 , Norm of product: tensor(11.58071423, device='cuda:0')\n",
      "epoch: 250 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(2.10831530e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 260 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  2.442526749746321e-07 , Norm of product: tensor(11.56993580, device='cuda:0')\n",
      "epoch: 260 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(1.90193077e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 270 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  1.7203072388838336e-07 , Norm of product: tensor(11.56191826, device='cuda:0')\n",
      "epoch: 270 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(1.91372450e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 280 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  8.481094937451417e-08 , Norm of product: tensor(11.55319309, device='cuda:0')\n",
      "epoch: 280 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(1.73204484e-07, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 290 gamma 0.0 lambda: 1.998201847076416\n",
      "MSE loss:  4.324571989400283e-08 , Norm of product: tensor(11.54553032, device='cuda:0')\n",
      "epoch: 290 gamma 0.0 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(1.54330792e-07, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gammaScheduler = 1.01\n",
    "gammaStopThreshold = 1e-5\n",
    "lambdaVal = torch.Tensor([4.]).to(device)\n",
    "minimumLambda = 2\n",
    "lambdaScheduler = 0.997\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if checkpointResume:\n",
    "    checkpointDictionary = torch.load(\"checkpoint.pth\")\n",
    "    optimizer.load_state_dict(checkpointDictionary[\"optimizerStateDict\"])\n",
    "    scheduler.load_state_dict(checkpointDictionary[\"schedulerState\"])\n",
    "    net.load_state_dict(checkpointDictionary[\"networkStateDict\"])\n",
    "    bestStateDict = checkpointDictionary[\"bestStateDict\"]\n",
    "    bestLoss = checkpointDictionary[\"bestLoss\"]\n",
    "    trainLosses = checkpointDictionary['trainLosses']\n",
    "    validationLosses = checkpointDictionary['validationLosses']\n",
    "    gamma = checkpointDictionary['gamma']\n",
    "    trainset = checkpointDictionary['trainSet']\n",
    "    testSet = checkpointDictionary['testSet']\n",
    "\n",
    "\n",
    "    # epoch = checkpointDictionary['maxEpoch']\n",
    "    startingEpoch = checkpointDictionary['epoch']\n",
    "    epoch = 1000\n",
    "else:\n",
    "\n",
    "    trainset, testSet = torch.utils.data.random_split(torch.utils.data.TensorDataset(torch.Tensor(XFull), torch.Tensor(YFull)), [trainSize, XFull.shape[0] - trainSize])\n",
    "    startingEpoch = 0\n",
    "    epoch = 300\n",
    "    trainLosses = []\n",
    "    validationLosses = []\n",
    "    # gamma = 1e-7\n",
    "    gamma = 0\n",
    "    bestStateDict = None\n",
    "    bestLoss = 100000\n",
    "    criterion = my_loss\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=train_batch_size, num_workers=2)\n",
    "loaders = {\"train\": trainloader, \"eval\": testLoader}\n",
    "\n",
    "\n",
    "for t in range(startingEpoch, epoch):\n",
    "    for phase in {\"train\", 'eval'}:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        tempValidationLosses = []\n",
    "        for i, (X, Y) in enumerate(loaders[phase]):\n",
    "\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            out = net(X)\n",
    "            loss = criterion(out, Y)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    # for j in range(numberOfLayers):\n",
    "                    #     net[2 * j].weight /= torch.maximum(torch.tensor([1.]).to(device), (torch.linalg.norm(net[2 * j].weight) / lambdaVal))\n",
    "            else:\n",
    "                tempValidationLosses.append(loss)\n",
    "                if loss < bestLoss:\n",
    "                    bestLoss = loss\n",
    "                    bestStateDict = net.state_dict()\n",
    "                    torch.save(bestStateDict, \"tempBestStateDict.pth\")\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "            # if gamma > gammaStopThreshold:\n",
    "            if gamma < gammaStopThreshold:\n",
    "                gamma *= gammaScheduler\n",
    "            if lambdaVal > minimumLambda:\n",
    "                lambdaVal *= lambdaScheduler\n",
    "            trainLosses.append(loss.item())\n",
    "            checkpointDictionary = \\\n",
    "                {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "                \"schedulerState\": scheduler.state_dict(),\n",
    "                 \"networkStateDict\": net.state_dict(),\n",
    "                 \"bestStateDict\": bestStateDict,\n",
    "                 \"bestLoss\": bestLoss,\n",
    "                 \"trainLosses\": trainLosses,\n",
    "                 \"validationLosses\": validationLosses,\n",
    "                 \"epoch\": t,\n",
    "                 \"maxEpoch\": epoch,\n",
    "                 \"gamma\": gamma,\n",
    "                 \"trainSet\": trainset,\n",
    "                 \"testSet\": testSet}\n",
    "            torch.save(checkpointDictionary, \"checkpoint.pth\")\n",
    "        else:\n",
    "            validationLosses.append(sum(tempValidationLosses[:-1]) / (len(tempValidationLosses) - 1))\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"epoch:\", t, \"gamma\", gamma, \"lambda:\", lambdaVal.item())\n",
    "            if phase == \"train\":\n",
    "                with torch.no_grad():\n",
    "                    prod = torch.linalg.norm(net[0].weight)\n",
    "                    for i in range(1, numberOfLayers):\n",
    "                        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "                    print('MSE loss: ', loss.item(), \", Norm of product:\", prod)\n",
    "            else:\n",
    "                print(\"validation losses average: \", validationLosses[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "checkpointDictionary = \\\n",
    "    {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "    \"schedulerState\": scheduler.state_dict(),\n",
    "     \"networkStateDict\": net.state_dict(),\n",
    "     \"bestStateDict\": bestStateDict,\n",
    "     \"bestLoss\": bestLoss,\n",
    "     \"trainLosses\": trainLosses,\n",
    "     \"validationLosses\": validationLosses,\n",
    "     \"epoch\": t,\n",
    "     \"maxEpoch\": epoch,\n",
    "     \"gamma\": gamma,\n",
    "     \"trainSet\": trainset,\n",
    "     \"testSet\": testSet}\n",
    "torch.save(checkpointDictionary, \"checkpoint.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.48641037940979, 4.712788343429565, 4.482716822624207, 4.7129652261734005)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 6\n",
    "device = torch.device(\"cpu\")\n",
    "net.to(device)\n",
    "lowerCoordinate = torch.Tensor([4.6975, 4.6975, 2.9975, 0.9499, -0.0001, -0.0001]).to(device)\n",
    "upperCoordinate = torch.Tensor([4.7025, 4.7025 ,3.0025, 0.9501,  0.0001,  0.0001 ]).to(device)\n",
    "inputData = (upperCoordinate - lowerCoordinate) * torch.rand(1000, dim, device=device) \\\n",
    "                                                        + lowerCoordinate\n",
    "plt.scatter(inputData[:, 0], inputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "outputData = net(inputData).detach().cpu().numpy()\n",
    "if lastDim == 3:\n",
    "    outputData = (A @ inputData.detach().cpu().numpy().T + B @ outputData.T + C).T\n",
    "plt.scatter(outputData[:, 0], outputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "plt.axis(\"equal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 4])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "lastDim = 2\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"tempBestStateDict.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainCompleteLoop = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss:  tensor(3.81713825e-08, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    print(\"1\")\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.9.pth\")\n",
    "else:\n",
    "    print(\"2\")\n",
    "    # torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.6.pth\")\n",
    "    torch.save(networkClass.state_dict(), \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(net)):\n",
    "    if i % 2 == 0:\n",
    "        weights.append(net[i].weight.clone().detach().cpu().numpy())\n",
    "        biases.append(net[i].bias.clone().detach().cpu().unsqueeze(1).numpy())\n",
    "torch.save({\"biases\": biases, \"weights\": weights, \"AMatrix\": A, \"BMatrix\": B}, \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.1.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11457, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}