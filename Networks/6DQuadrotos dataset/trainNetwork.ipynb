{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "torch.set_printoptions(precision=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainCompleteLoop = False\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "fileName = \"fourDimTrainData.mat\"\n",
    "# data = loadmat(fileName)\n",
    "# XFull = data['X']\n",
    "# YFull = data['y']\n",
    "data = loadmat(fileName)\n",
    "XFull = data['Xtrain']\n",
    "YFull = data['Ytrain']\n",
    "A = data['A']\n",
    "B = data['B']\n",
    "if XFull.shape[0] < XFull.shape[1]:\n",
    "    XFull = XFull.T\n",
    "    YFull = YFull.T\n",
    "if \"quad\" in fileName:\n",
    "    A = np.zeros((6, 6), dtype=np.float32)\n",
    "    A[0, 3] = 1.\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3), dtype=np.float32)\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1), dtype=np.float32)\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "    lastDim = 3\n",
    "elif \"doubleIntegrator\" in fileName:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "    lastDim = 1\n",
    "elif \"fourDim\" in fileName:\n",
    "    pass\n",
    "    lastDim = 2\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "if trainCompleteLoop:\n",
    "    YFull = (A @ XFull.T + B @ YFull.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "dataSplit = 0.9\n",
    "trainSize = int(dataSplit * XFull.shape[0])\n",
    "\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, lastDim),)\n",
    "\n",
    "# net = nn.Sequential(\n",
    "#     nn.Linear(6, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, lastDim))\n",
    "numberOfLayers = (len(net) + 1) // 2\n",
    "net.to(device)\n",
    "train_batch_size = 64\n",
    "\n",
    "def my_loss(output, target):\n",
    "    prod = torch.linalg.norm(net[0].weight)\n",
    "    for i in range(1, numberOfLayers):\n",
    "        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "    loss = torch.mean((output - target)**2) + gamma * prod\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(73766, 2)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YFull.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "checkpointResume = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 gamma 0 lambda: 4.0\n",
      "validation losses average:  tensor(0.53080660, grad_fn=<DivBackward0>)\n",
      "epoch: 0 gamma 0.0 lambda: 3.98799991607666\n",
      "MSE loss:  7.538383943028748e-05 , Norm of product: tensor(12.79885292)\n",
      "epoch: 10 gamma 0.0 lambda: 3.881606340408325\n",
      "validation losses average:  tensor(5.53796053e-06, grad_fn=<DivBackward0>)\n",
      "epoch: 10 gamma 0.0 lambda: 3.8699615001678467\n",
      "MSE loss:  2.296250869449068e-07 , Norm of product: tensor(11.93804932)\n",
      "epoch: 20 gamma 0.0 lambda: 3.766716718673706\n",
      "validation losses average:  tensor(3.51238242e-07, grad_fn=<DivBackward0>)\n",
      "epoch: 20 gamma 0.0 lambda: 3.7554163932800293\n",
      "MSE loss:  8.108876414780752e-08 , Norm of product: tensor(12.62972927)\n",
      "epoch: 30 gamma 0.0 lambda: 3.6552278995513916\n",
      "validation losses average:  tensor(8.29515557e-07, grad_fn=<DivBackward0>)\n",
      "epoch: 30 gamma 0.0 lambda: 3.6442620754241943\n",
      "MSE loss:  2.366031992551143e-08 , Norm of product: tensor(13.15942669)\n",
      "epoch: 40 gamma 0.0 lambda: 3.5470387935638428\n",
      "validation losses average:  tensor(6.24794172e-09, grad_fn=<DivBackward0>)\n",
      "epoch: 40 gamma 0.0 lambda: 3.536397695541382\n",
      "MSE loss:  1.5253007745741343e-08 , Norm of product: tensor(13.16123390)\n",
      "epoch: 50 gamma 0.0 lambda: 3.4420523643493652\n",
      "validation losses average:  tensor(3.91305477e-08, grad_fn=<DivBackward0>)\n",
      "epoch: 50 gamma 0.0 lambda: 3.4317262172698975\n",
      "MSE loss:  2.4001471956580644e-06 , Norm of product: tensor(12.99740601)\n",
      "epoch: 60 gamma 0.0 lambda: 3.34017276763916\n",
      "validation losses average:  tensor(3.76889719e-09, grad_fn=<DivBackward0>)\n",
      "epoch: 60 gamma 0.0 lambda: 3.3301522731781006\n",
      "MSE loss:  7.393800238730819e-09 , Norm of product: tensor(12.83506393)\n",
      "epoch: 70 gamma 0.0 lambda: 3.2413089275360107\n",
      "validation losses average:  tensor(2.14791999e-05, grad_fn=<DivBackward0>)\n",
      "epoch: 70 gamma 0.0 lambda: 3.2315850257873535\n",
      "MSE loss:  2.8585569111783116e-07 , Norm of product: tensor(12.70382500)\n",
      "epoch: 80 gamma 0.0 lambda: 3.145371437072754\n",
      "validation losses average:  tensor(7.00594853e-08, grad_fn=<DivBackward0>)\n",
      "epoch: 80 gamma 0.0 lambda: 3.1359353065490723\n",
      "MSE loss:  5.218200982426424e-09 , Norm of product: tensor(12.64056015)\n",
      "epoch: 90 gamma 0.0 lambda: 3.052273750305176\n",
      "validation losses average:  tensor(3.04800295e-07, grad_fn=<DivBackward0>)\n",
      "epoch: 90 gamma 0.0 lambda: 3.043116807937622\n",
      "MSE loss:  3.7768252525438584e-08 , Norm of product: tensor(12.57662487)\n",
      "epoch: 100 gamma 0.0 lambda: 2.961930990219116\n",
      "validation losses average:  tensor(4.06645029e-08, grad_fn=<DivBackward0>)\n",
      "epoch: 100 gamma 0.0 lambda: 2.953045129776001\n",
      "MSE loss:  5.0516115734922096e-09 , Norm of product: tensor(12.52529240)\n",
      "epoch: 110 gamma 0.0 lambda: 2.8742623329162598\n",
      "validation losses average:  tensor(1.05486586e-09, grad_fn=<DivBackward0>)\n",
      "epoch: 110 gamma 0.0 lambda: 2.8656394481658936\n",
      "MSE loss:  6.543751651655327e-10 , Norm of product: tensor(12.49363613)\n",
      "epoch: 120 gamma 0.0 lambda: 2.7891886234283447\n",
      "validation losses average:  tensor(9.26758725e-10, grad_fn=<DivBackward0>)\n",
      "epoch: 120 gamma 0.0 lambda: 2.7808210849761963\n",
      "MSE loss:  5.915818945823048e-10 , Norm of product: tensor(12.48510361)\n",
      "epoch: 130 gamma 0.0 lambda: 2.7066333293914795\n",
      "validation losses average:  tensor(5.87027427e-10, grad_fn=<DivBackward0>)\n",
      "epoch: 130 gamma 0.0 lambda: 2.6985132694244385\n",
      "MSE loss:  9.067731809864199e-08 , Norm of product: tensor(12.47702122)\n",
      "epoch: 140 gamma 0.0 lambda: 2.626520872116089\n",
      "validation losses average:  tensor(3.31596567e-07, grad_fn=<DivBackward0>)\n",
      "epoch: 140 gamma 0.0 lambda: 2.6186411380767822\n",
      "MSE loss:  3.819727645293369e-09 , Norm of product: tensor(12.47517490)\n",
      "epoch: 150 gamma 0.0 lambda: 2.5487794876098633\n",
      "validation losses average:  tensor(1.24821256e-07, grad_fn=<DivBackward0>)\n",
      "epoch: 150 gamma 0.0 lambda: 2.541133165359497\n",
      "MSE loss:  5.099281552567447e-10 , Norm of product: tensor(12.46561337)\n",
      "epoch: 160 gamma 0.0 lambda: 2.473339557647705\n",
      "validation losses average:  tensor(1.48468018e-06, grad_fn=<DivBackward0>)\n",
      "epoch: 160 gamma 0.0 lambda: 2.4659194946289062\n",
      "MSE loss:  1.5500665639933686e-08 , Norm of product: tensor(12.45984077)\n",
      "epoch: 170 gamma 0.0 lambda: 2.400132417678833\n",
      "validation losses average:  tensor(7.29829850e-08, grad_fn=<DivBackward0>)\n",
      "epoch: 170 gamma 0.0 lambda: 2.3929319381713867\n",
      "MSE loss:  2.0041907022871897e-10 , Norm of product: tensor(12.45379353)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 44>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     49\u001B[0m     net\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     50\u001B[0m tempValidationLosses \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (X, Y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loaders[phase]):\n\u001B[1;32m     53\u001B[0m     X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     54\u001B[0m     Y \u001B[38;5;241m=\u001B[39m Y\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[0;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1207\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1207\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1210\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1173\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1169\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1170\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1171\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1172\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1173\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1175\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1011\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    998\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1000\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1008\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1009\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1010\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1011\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1012\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1013\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1014\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1015\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1016\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.9/3.9.12/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py:122\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rlock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# unserialize the data after having released the lock\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ForkingPickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:307\u001B[0m, in \u001B[0;36mrebuild_storage_filename\u001B[0;34m(cls, manager, handle, size)\u001B[0m\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    304\u001B[0m         os\u001B[38;5;241m.\u001B[39mclose(fd)\n\u001B[0;32m--> 307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrebuild_storage_filename\u001B[39m(\u001B[38;5;28mcls\u001B[39m, manager, handle, size):\n\u001B[1;32m    308\u001B[0m     storage \u001B[38;5;241m=\u001B[39m storage_from_cache(\u001B[38;5;28mcls\u001B[39m, handle)\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m storage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "gammaScheduler = 1.01\n",
    "gammaStopThreshold = 1e-5\n",
    "lambdaVal = torch.Tensor([4.]).to(device)\n",
    "minimumLambda = 2\n",
    "lambdaScheduler = 0.997\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if checkpointResume:\n",
    "    checkpointDictionary = torch.load(\"checkpoint.pth\")\n",
    "    optimizer.load_state_dict(checkpointDictionary[\"optimizerStateDict\"])\n",
    "    scheduler.load_state_dict(checkpointDictionary[\"schedulerState\"])\n",
    "    net.load_state_dict(checkpointDictionary[\"networkStateDict\"])\n",
    "    bestStateDict = checkpointDictionary[\"bestStateDict\"]\n",
    "    bestLoss = checkpointDictionary[\"bestLoss\"]\n",
    "    trainLosses = checkpointDictionary['trainLosses']\n",
    "    validationLosses = checkpointDictionary['validationLosses']\n",
    "    gamma = checkpointDictionary['gamma']\n",
    "    trainset = checkpointDictionary['trainSet']\n",
    "    testSet = checkpointDictionary['testSet']\n",
    "\n",
    "\n",
    "    # epoch = checkpointDictionary['maxEpoch']\n",
    "    startingEpoch = checkpointDictionary['epoch']\n",
    "    epoch = 1000\n",
    "else:\n",
    "\n",
    "    trainset, testSet = torch.utils.data.random_split(torch.utils.data.TensorDataset(torch.Tensor(XFull), torch.Tensor(YFull)), [trainSize, XFull.shape[0] - trainSize])\n",
    "    startingEpoch = 0\n",
    "    epoch = 300\n",
    "    trainLosses = []\n",
    "    validationLosses = []\n",
    "    # gamma = 1e-7\n",
    "    gamma = 0\n",
    "    bestStateDict = None\n",
    "    bestLoss = 100000\n",
    "    criterion = my_loss\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=train_batch_size, num_workers=2)\n",
    "loaders = {\"train\": trainloader, \"eval\": testLoader}\n",
    "\n",
    "\n",
    "for t in range(startingEpoch, epoch):\n",
    "    for phase in {\"train\", 'eval'}:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        tempValidationLosses = []\n",
    "        for i, (X, Y) in enumerate(loaders[phase]):\n",
    "\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            out = net(X)\n",
    "            loss = criterion(out, Y)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    # for j in range(numberOfLayers):\n",
    "                    #     net[2 * j].weight /= torch.maximum(torch.tensor([1.]).to(device), (torch.linalg.norm(net[2 * j].weight) / lambdaVal))\n",
    "            else:\n",
    "                tempValidationLosses.append(loss)\n",
    "                if loss < bestLoss:\n",
    "                    bestLoss = loss\n",
    "                    bestStateDict = net.state_dict()\n",
    "                    torch.save(bestStateDict, \"tempBestStateDict.pth\")\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "            # if gamma > gammaStopThreshold:\n",
    "            if gamma < gammaStopThreshold:\n",
    "                gamma *= gammaScheduler\n",
    "            if lambdaVal > minimumLambda:\n",
    "                lambdaVal *= lambdaScheduler\n",
    "            trainLosses.append(loss.item())\n",
    "            checkpointDictionary = \\\n",
    "                {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "                \"schedulerState\": scheduler.state_dict(),\n",
    "                 \"networkStateDict\": net.state_dict(),\n",
    "                 \"bestStateDict\": bestStateDict,\n",
    "                 \"bestLoss\": bestLoss,\n",
    "                 \"trainLosses\": trainLosses,\n",
    "                 \"validationLosses\": validationLosses,\n",
    "                 \"epoch\": t,\n",
    "                 \"maxEpoch\": epoch,\n",
    "                 \"gamma\": gamma,\n",
    "                 \"trainSet\": trainset,\n",
    "                 \"testSet\": testSet}\n",
    "            torch.save(checkpointDictionary, \"checkpoint.pth\")\n",
    "        else:\n",
    "            validationLosses.append(sum(tempValidationLosses[:-1]) / (len(tempValidationLosses) - 1))\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"epoch:\", t, \"gamma\", gamma, \"lambda:\", lambdaVal.item())\n",
    "            if phase == \"train\":\n",
    "                with torch.no_grad():\n",
    "                    prod = torch.linalg.norm(net[0].weight)\n",
    "                    for i in range(1, numberOfLayers):\n",
    "                        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "                    print('MSE loss: ', loss.item(), \", Norm of product:\", prod)\n",
    "            else:\n",
    "                print(\"validation losses average: \", validationLosses[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "checkpointDictionary = \\\n",
    "    {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "    \"schedulerState\": scheduler.state_dict(),\n",
    "     \"networkStateDict\": net.state_dict(),\n",
    "     \"bestStateDict\": bestStateDict,\n",
    "     \"bestLoss\": bestLoss,\n",
    "     \"trainLosses\": trainLosses,\n",
    "     \"validationLosses\": validationLosses,\n",
    "     \"epoch\": t,\n",
    "     \"maxEpoch\": epoch,\n",
    "     \"gamma\": gamma,\n",
    "     \"trainSet\": trainset,\n",
    "     \"testSet\": testSet}\n",
    "torch.save(checkpointDictionary, \"checkpoint.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.48641037940979, 4.712788343429565, 4.482716822624207, 4.7129652261734005)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPyElEQVR4nO3df6jd9X3H8eeryWg3VtvYXFnxqrd1OrsN0fVsKw0r4rYoJIRushKLI/5Rs/7RKXarIzBwxD/qfjbbKKwaBlKxKUgpqYVKILOwMofnomsxUl3VTqU2t0narZuz1rz3x/1mPfd6f5yb3NxzzyfPB3y553w+n5O88vHkle/93nOOqSokSe1606gDSJLOLotekhpn0UtS4yx6SWqcRS9Jjds46gDzbd68uaampkYdQ5LGyvT09PeqamKhuXVX9FNTU/T7/VHHkKSxkuTbi8156UaSGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1bt29vFKSAA49+TJ/+sVv8N3/+tGc8Xf8zE+x+wPv5g+u+fkRJRs/Q5/RJ9mQ5PEkDy0w96kkT3TH00m+PzC3K8kz3bFrlXJLatihJ1/mls9Ov6HkAY79z2t88ivf5DOP/PsIko2nlVy6uQ14aqGJqrq9qq6qqquAvwe+AJDkfOBO4NeBXwPuTLLpjBJLat7fHX5m2TWf/Mo31yBJG4Yq+iSTwDZg/xDLbwQ+192+DjhUVcer6gRwCLj+dIJKOnd88zv/OeoITRn2jH4fcAdwcqlFSS4B3gUc7oYuBF4YWPJiNyZJi/rRkk2jlVq26JNsB45W1fQQv95O4MGqen0lIZLsTtJP0p+ZmVnJQyVJyxjmjH4LsCPJ88AB4Nok9y+ydic/uWwD8BJw0cD9yW5sjqq6p6p6VdWbmFjww9cknUM2ZtQJ2rJs0VfVnqqarKopZov8cFXdNH9dkiuATcC/DAw/DGxNsqn7IezWbkySFnXZBT876ghNOe03TCXZm2THwNBO4EBV1amBqjoO3AU81h17uzFJWtTHt/7CsmveN+UL+IaVgV5eF3q9Xvl59JIOPfkyuz87zUIN9b6pTRz46PvXPNN6lmS6qnoLzfnOWEnr0m//0s/x3N3bRh2jCX7WjSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklq3NBFn2RDkseTPLTI/IeSHEnyZJIHBsZfT/JEdxxcjdCSpOFtXMHa24CngPPmTyS5DNgDbKmqE0kuGJh+paquOqOUkqTTNtQZfZJJYBuwf5EltwCfrqoTAFV1dHXiSZLO1LCXbvYBdwAnF5m/HLg8ydeSPJrk+oG5tyTpd+MfXOjBSXZ3a/ozMzPDZpckDWHZok+yHThaVdNLLNsIXAZcA9wI3Jvk7d3cJVXVAz4M7Ety6fwHV9U9VdWrqt7ExMQK/wiSpKUMc0a/BdiR5HngAHBtkvvnrXkROFhVr1XVc8DTzBY/VfVS9/VZ4BHg6tWJLkkaxrJFX1V7qmqyqqaAncDhqrpp3rIvMns2T5LNzF7KeTbJpiRvHhjfAhxZtfSSpGWd9uvok+xNsqO7+zBwLMkR4J+AT1TVMeA9QD/Jv3Xjd1eVRS9JayhVNeoMc/R6ver3+6OOIUljJcl09/PQN/CdsZLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcUMXfZINSR5P8tAi8x9KciTJk0keGBjfleSZ7ti1GqElScPbuIK1twFPAefNn0hyGbAH2FJVJ5Jc0I2fD9wJ9IACppMcrKoTZ5xckjSUoc7ok0wC24D9iyy5Bfj0qQKvqqPd+HXAoao63s0dAq4/s8iSpJUY9tLNPuAO4OQi85cDlyf5WpJHk5wq8wuBFwbWvdiNzZFkd5J+kv7MzMyQkSRJw1i26JNsB45W1fQSyzYClwHXADcC9yZ5+7AhquqequpVVW9iYmLYh0mShjDMGf0WYEeS54EDwLVJ7p+35kXgYFW9VlXPAU8zW/wvARcNrJvsxiRJa2TZoq+qPVU1WVVTwE7gcFXdNG/ZF5k9myfJZmYv5TwLPAxsTbIpySZgazcmSVojK3nVzRxJ9gL9qjrITwr9CPA68ImqOtatuwt4rHvY3qo6foaZJUkrkKoadYY5er1e9fv9UceQpLGSZLqqegvN+c5YSWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktS4oYs+yYYkjyd5aIG5m5PMJHmiOz4yMPf6wPjB1QouSRrOxhWsvQ14CjhvkfnPV9XHFhh/paquWmkwSdLqGOqMPskksA3Yf3bjSJJW27CXbvYBdwAnl1hzQ5KvJ3kwyUUD429J0k/yaJIPLvTAJLu7Nf2ZmZkhI0mShrFs0SfZDhytquklln0JmKqqK4FDwH0Dc5dUVQ/4MLAvyaXzH1xV91RVr6p6ExMTK/sTSJKWNMwZ/RZgR5LngQPAtUnuH1xQVceq6tXu7n7gvQNzL3VfnwUeAa4+89iSpGEtW/RVtaeqJqtqCtgJHK6qmwbXJHnnwN0dzP7QliSbkry5u72Z2X80jqxSdknSEFbyqps5kuwF+lV1ELg1yQ7gx8Bx4OZu2XuAzyQ5yew/KndXlUUvSWsoVTXqDHP0er3q9/ujjiFJYyXJdPfz0DfwnbGS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXFDF32SDUkeT/LQAnM3J5lJ8kR3fGRgbleSZ7pj12oFlyQNZ+MK1t4GPAWct8j856vqY4MDSc4H7gR6QAHTSQ5W1YnTCStJWrmhzuiTTALbgP0r/PWvAw5V1fGu3A8B16/w15AknYFhz+j3AXcAb11izQ1JPgA8DdxeVS8AFwIvDKx5sRubI8luYDfAxRdfPGSkc8xfXg7//d2f3H/bxfB7/wiTvzq6TJLGwrJn9Em2A0eranqJZV8CpqrqSmbP2u9bSYiquqeqelXVm5iYWMlDzw3zSx7gB/8B+38LvvzHo8kkaWwMc+lmC7AjyfPAAeDaJPcPLqiqY1X1and3P/De7vZLwEUDSye7Ma3E/JIf9Ni98M9/u3ZZJI2dZYu+qvZU1WRVTQE7gcNVddPgmiTvHLi7g9kf2gI8DGxNsinJJmBrN6bV9NW/GHUCSevYSl51M0eSvUC/qg4CtybZAfwYOA7cDFBVx5PcBTzWPWxvVR0/s8h6g9d+OOoEktaxVNWoM8zR6/Wq3++POsb68ldXwA+/s/SaP/vB2mSRtC4lma6q3kJzvjN2HGz/61EnkDTGLPpxcMU2+OnNo04haUxZ9OPiT74Fb7tk4bkrb1zbLJLGymn/MFYjcPvXZ7/+4EU4eCu8/A249Dfhd/9htLkkrWsW/Th62yT8/hdGnULSmPDSjSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWrcuvusmyQzwLfX6LfbDHxvjX6v1Wb20TD76Ixz/rXIfklVLfg/9Fh3Rb+WkvQX+xCg9c7so2H20Rnn/KPO7qUbSWqcRS9JjTvXi/6eUQc4A2YfDbOPzjjnH2n2c/oavSSdC871M3pJap5FL0mNa7bok2xI8niSh5ZYc0OSStLr7k8leSXJE90xkg96Xyp7kpuTzAxk/MjA3K4kz3THrrVN/f8ZTjf76wPjB9c29ZyMSz5vknwoyZEkTyZ5YGB8Xe99N79Y9pHv/TLPm08N5Hs6yfcH5tb1vi+Tfc32veXPo78NeAo4b6HJJG/t1vzrvKlvVdVVZzfaspbMDny+qj42OJDkfOBOoAcUMJ3kYFWdOKtJ32jF2TuvrIN9hyXyJ7kM2ANsqaoTSS7oxtf93i+WvbMe9n7R7FV1+6nbSf4QuLq7ve73fbHsnTXb9ybP6JNMAtuA/Ussuwv4c+B/1yTUkIbMvpDrgENVdbx7oh8Crl/tfEs5g+zrwhD5bwE+fapIqupoNz4Oe79Y9pFb4fPmRuBz3e1x2PdBg9nXVJNFD+wD7gBOLjSZ5FeAi6rqywtMv6v7NuyrSX7jLGZczD6WyN65IcnXkzyY5KJu7ELghYE1L3Zja2kfp5cd4C1J+kkeTfLBsxlyCftYOv/lwOVJvtblPFUq47D3i2WH0e/9PpZ/3pDkEuBdwOFuaBz2HVgwO6zhvjdX9Em2A0eranqR+TcBfwP80QLT3wEurqqrgY8DDyRZ7BLEqlsue+dLwFRVXcnsGcx9axJuGauQ/ZLuLeIfBvYlufTspX2jIfNvBC4DrmH27OzeJG8/++mWtgrZR7b3Q2Y/ZSfwYFW9fpZjDWUVsq/ZvjdX9MAWYEeS54EDwLVJ7h+Yfyvwy8Aj3Zr3AQeT9Krq1ao6BtD9x/sWs2dC6yU7VXWsql7t7u4H3tvdfgkYPEOe7MbWyplkp6pe6r4+CzzC3GuZa2HZ/MyeMR6sqteq6jngaWbLc93vPYtnH/XeD5P9lJ3MvfQxDvt+yvzsa7vvVdXswezZy0PLrHkE6HW3J4AN3e13M/ukOX89ZQfeOXD7d4BHu9vnA88Bm7rjuTHKvgl4c3d7M/AM8Ivr7XnD7PXf+wZyvgC8Y0z2frHs62bvl/r7ClwBPE/3Js9ubN3v+xLZ13TfW37VzRxJ9gL9qlrqZUwfAPYmeY3Za24frarjaxJwCfOy35pkB/Bj4DhwM0BVHU9yF/BY97C945IdeA/wmSQnmf0u8+6qOjKKvPPNy/8wsDXJEeB14BPVfQc4Bnu/YPYk72cd7v0Cf193Ageqa0YYm+c8LJCdNX7O+xEIktS4Fq/RS5IGWPSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcf8HrfSrpBW2gRoAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 6\n",
    "device = torch.device(\"cpu\")\n",
    "net.to(device)\n",
    "lowerCoordinate = torch.Tensor([4.6975, 4.6975, 2.9975, 0.9499, -0.0001, -0.0001]).to(device)\n",
    "upperCoordinate = torch.Tensor([4.7025, 4.7025 ,3.0025, 0.9501,  0.0001,  0.0001 ]).to(device)\n",
    "inputData = (upperCoordinate - lowerCoordinate) * torch.rand(1000, dim, device=device) \\\n",
    "                                                        + lowerCoordinate\n",
    "plt.scatter(inputData[:, 0], inputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "outputData = net(inputData).detach().cpu().numpy()\n",
    "if lastDim == 3:\n",
    "    outputData = (A @ inputData.detach().cpu().numpy().T + B @ outputData.T + C).T\n",
    "plt.scatter(outputData[:, 0], outputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "plt.axis(\"equal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 6])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "lastDim = 6\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"tempBestStateDict.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainCompleteLoop = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss:  tensor(1.17401339e-10, grad_fn=<AddBackward0>)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    print(\"1\")\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.9.pth\")\n",
    "else:\n",
    "    print(\"2\")\n",
    "    # torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.6.pth\")\n",
    "    torch.save(networkClass.state_dict(), \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(net)):\n",
    "    if i % 2 == 0:\n",
    "        weights.append(net[i].weight.clone().detach().cpu().numpy())\n",
    "        biases.append(net[i].bias.clone().detach().cpu().unsqueeze(1).numpy())\n",
    "torch.save({\"biases\": biases, \"weights\": weights, \"AMatrix\": A, \"BMatrix\": B}, \"../fourDimV1.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.1.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11457, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}