{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "\n",
    "\n",
    "\n",
    "def export2matlab(file_name, net, A, B, save_model=False):\n",
    "    '''\n",
    "    Export pytorch fully connected network to matlab\n",
    "\n",
    "    '''\n",
    "\n",
    "    num_layers = int((len(net) - 1) / 2)\n",
    "    dim_in = float(net[0].weight.shape[1])\n",
    "    dim_out = float(net[-1].weight.shape[0])\n",
    "    hidden_dims = [float(net[2 * i].weight.shape[0]) for i in range(0, num_layers)]\n",
    "\n",
    "    # network dimensions\n",
    "    dims = [dim_in] + hidden_dims + [dim_out]\n",
    "\n",
    "    # get weights\n",
    "    # weights = np.zeros((num_layers+1,))\n",
    "    weights = [net[2 * i].weight.detach().numpy().astype(np.float64) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    # get biases\n",
    "    # biases = np.zeros((num_layers+1,))\n",
    "    biases = [net[2 * i].bias.detach().numpy().astype(np.float64).reshape(-1, 1) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    activation = str(net[1])[0:-2].lower()\n",
    "\n",
    "    # export network data to matlab\n",
    "    data = {}\n",
    "    data['net'] = {'weights': weights, 'biases': biases, 'dims': dims, 'activation': activation, 'name': file_name}\n",
    "    data['AMatrix'] = A\n",
    "    data['BMatrix'] = B\n",
    "\n",
    "    scipy.io.savemat(file_name + '.mat', data)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "trainCompleteLoop = True\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "\n",
    "data = loadmat(\"trainDataQuad.mat\")\n",
    "Xtrain = data['X']\n",
    "Ytrain = data['y']\n",
    "# data = loadmat(\"quadRotorTrainData.mat\")\n",
    "# Xtrain = data['Xtrain']\n",
    "# Ytrain = data['Ytrain']\n",
    "# A = data['A']\n",
    "# B = data['B']\n",
    "if True:\n",
    "    A = np.zeros((6, 6))\n",
    "    A[0, 3] = 1\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3))\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1))\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "\n",
    "else:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "lastDim = 3\n",
    "if trainCompleteLoop:\n",
    "    Ytrain = (A @ Xtrain.T + B @ Ytrain.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "trainset = torch.utils.data.TensorDataset(torch.Tensor(Xtrain), torch.Tensor(Ytrain))\n",
    "\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, lastDim))\n",
    "\n",
    "train_batch_size = 128\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "epoch = 2000\n",
    "net.train()\n",
    "losses = []\n",
    "\n",
    "def my_loss(output, target):\n",
    "    gamma = 0.2\n",
    "    loss = torch.mean((output - target)**2) \\\n",
    "           # + gamma * torch.linalg.norm(net[-1].weight) \\\n",
    "           #                                      * torch.linalg.norm(net[-3].weight) \\\n",
    "           #                                      * torch.linalg.norm(net[-5].weight)\n",
    "    return loss\n",
    "bestStateDic = None\n",
    "bestLoss = 100000\n",
    "criterion = my_loss\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "for t in range(epoch):\n",
    "    for i, (X, Y) in enumerate(trainloader):\n",
    "        out = net(X)\n",
    "        loss = criterion(out, Y)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optimizer.zero_grad()\n",
    "            for i in [0, 2, 4]:\n",
    "                net[i].weight /= torch.maximum(torch.tensor([1]), (torch.linalg.norm(net[i].weight) / 1.))\n",
    "\n",
    "            if loss < bestLoss:\n",
    "                bestLoss = loss\n",
    "                bestStateDic = net.state_dict()\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    if (np.mod(t, 10) == 0):\n",
    "        print('epoch: ', t, 'MSE loss: ', loss.item())\n",
    "        print(torch.linalg.norm(net[0].weight) * torch.linalg.norm(net[2].weight) * torch.linalg.norm(net[4].weight))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "layers = []\n",
    "dimensions = [6, 32, 32, lastDim]\n",
    "for i in range(len(dimensions) - 1):\n",
    "    layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "    if i < len(dimensions) - 2:\n",
    "        layers.append(nn.ReLU())\n",
    "network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = network\n",
    "torch.save(networkClass.state_dict(), \"../quadRotorCompleteLoopVq.0.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = loadmat(\"trainDataQuad.mat\")\n",
    "Xtrain = data['X']\n",
    "Ytrain = data['y']\n",
    "Xtrain.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}