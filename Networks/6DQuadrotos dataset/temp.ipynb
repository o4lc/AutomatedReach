{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "\n",
    "def export2matlab(file_name, net, A, B, save_model=False):\n",
    "    '''\n",
    "    Export pytorch fully connected network to matlab\n",
    "\n",
    "    '''\n",
    "\n",
    "    num_layers = int((len(net) - 1) / 2)\n",
    "    dim_in = float(net[0].weight.shape[1])\n",
    "    dim_out = float(net[-1].weight.shape[0])\n",
    "    hidden_dims = [float(net[2 * i].weight.shape[0]) for i in range(0, num_layers)]\n",
    "\n",
    "    # network dimensions\n",
    "    dims = [dim_in] + hidden_dims + [dim_out]\n",
    "\n",
    "    # get weights\n",
    "    # weights = np.zeros((num_layers+1,))\n",
    "    weights = [net[2 * i].weight.detach().numpy().astype(np.float64) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    # get biases\n",
    "    # biases = np.zeros((num_layers+1,))\n",
    "    biases = [net[2 * i].bias.detach().numpy().astype(np.float64).reshape(-1, 1) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    activation = str(net[1])[0:-2].lower()\n",
    "\n",
    "    # export network data to matlab\n",
    "    data = {}\n",
    "    data['net'] = {'weights': weights, 'biases': biases, 'dims': dims, 'activation': activation, 'name': file_name}\n",
    "    data['AMatrix'] = A\n",
    "    data['BMatrix'] = B\n",
    "\n",
    "\n",
    "    scipy.io.savemat(file_name + '.mat', data)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainCompleteLoop = False\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "\n",
    "data = loadmat(\"trainDataQuad.mat\")\n",
    "XFull = data['X']\n",
    "YFull = data['y']\n",
    "# data = loadmat(\"quadRotorTrainData.mat\")\n",
    "# Xtrain = data['Xtrain']\n",
    "# Ytrain = data['Ytrain']\n",
    "# A = data['A']\n",
    "# B = data['B']\n",
    "if True:\n",
    "    A = np.zeros((6, 6), dtype=np.float32)\n",
    "    A[0, 3] = 1.\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3), dtype=np.float32)\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1), dtype=np.float32)\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "\n",
    "else:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "lastDim = 3\n",
    "if trainCompleteLoop:\n",
    "    YFull = (A @ XFull.T + B @ YFull.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "dataSplit = 0.9\n",
    "trainSize = int(dataSplit * XFull.shape[0])\n",
    "\n",
    "\n",
    "# net = nn.Sequential(\n",
    "#     nn.Linear(6, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 16),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(16, lastDim))\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, lastDim))\n",
    "numberOfLayers = (len(net) + 1) // 2\n",
    "net.to(device)\n",
    "train_batch_size = 64\n",
    "\n",
    "def my_loss(output, target):\n",
    "    prod = torch.linalg.norm(net[0].weight)\n",
    "    for i in range(1, numberOfLayers):\n",
    "        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "    loss = torch.mean((output - target)**2) + gamma * prod\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "checkpointResume = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 gamma 1e-07 lambda: 4.0\n",
      "validation losses average:  tensor(4.37616253, grad_fn=<DivBackward0>)\n",
      "epoch: 0 gamma 1.0099999999999999e-07 lambda: 3.98799991607666\n",
      "MSE loss:  0.1386428028345108 , Norm of product: tensor(353.42010498)\n",
      "epoch: 10 gamma 1.1046221254112044e-07 lambda: 3.881606340408325\n",
      "validation losses average:  tensor(0.00444478, grad_fn=<DivBackward0>)\n",
      "epoch: 10 gamma 1.1156683466653164e-07 lambda: 3.8699615001678467\n",
      "MSE loss:  0.0024411946069449186 , Norm of product: tensor(438.34466553)\n",
      "epoch: 20 gamma 1.220190039947967e-07 lambda: 3.766716718673706\n",
      "validation losses average:  tensor(0.00210806, grad_fn=<DivBackward0>)\n",
      "epoch: 20 gamma 1.2323919403474465e-07 lambda: 3.7554163932800293\n",
      "MSE loss:  0.0007468006224371493 , Norm of product: tensor(409.82638550)\n",
      "epoch: 30 gamma 1.347848915332906e-07 lambda: 3.6552278995513916\n",
      "validation losses average:  tensor(0.00043278, grad_fn=<DivBackward0>)\n",
      "epoch: 30 gamma 1.361327404486235e-07 lambda: 3.6442620754241943\n",
      "MSE loss:  0.00031742072314955294 , Norm of product: tensor(381.40789795)\n",
      "epoch: 40 gamma 1.4888637335882214e-07 lambda: 3.5470387935638428\n",
      "validation losses average:  tensor(0.00038730, grad_fn=<DivBackward0>)\n",
      "epoch: 40 gamma 1.5037523709241035e-07 lambda: 3.536397695541382\n",
      "MSE loss:  0.00023508878075517714 , Norm of product: tensor(354.24295044)\n",
      "epoch: 50 gamma 1.6446318218438825e-07 lambda: 3.4420523643493652\n",
      "validation losses average:  tensor(0.00023258, grad_fn=<DivBackward0>)\n",
      "epoch: 50 gamma 1.6610781400623213e-07 lambda: 3.4317262172698975\n",
      "MSE loss:  0.00014528227620758116 , Norm of product: tensor(331.00753784)\n",
      "epoch: 60 gamma 1.8166966985640915e-07 lambda: 3.34017276763916\n",
      "validation losses average:  tensor(0.00015551, grad_fn=<DivBackward0>)\n",
      "epoch: 60 gamma 1.8348636655497324e-07 lambda: 3.3301522731781006\n",
      "MSE loss:  0.00012614682782441378 , Norm of product: tensor(311.03900146)\n",
      "epoch: 70 gamma 2.0067633683953852e-07 lambda: 3.2413089275360107\n",
      "validation losses average:  tensor(0.00018862, grad_fn=<DivBackward0>)\n",
      "epoch: 70 gamma 2.0268310020793392e-07 lambda: 3.2315850257873535\n",
      "MSE loss:  9.845955355558544e-05 , Norm of product: tensor(295.14422607)\n",
      "epoch: 80 gamma 2.2167152171942588e-07 lambda: 3.145371437072754\n",
      "validation losses average:  tensor(0.00019202, grad_fn=<DivBackward0>)\n",
      "epoch: 80 gamma 2.2388823693662014e-07 lambda: 3.1359353065490723\n",
      "MSE loss:  0.0002033848431892693 , Norm of product: tensor(284.33517456)\n",
      "epoch: 90 gamma 2.4486326746484827e-07 lambda: 3.052273750305176\n",
      "validation losses average:  tensor(0.00105335, grad_fn=<DivBackward0>)\n",
      "epoch: 90 gamma 2.4731190013949676e-07 lambda: 3.043116807937622\n",
      "MSE loss:  0.0009660543873906136 , Norm of product: tensor(264.92141724)\n",
      "epoch: 100 gamma 2.70481382942153e-07 lambda: 2.961930990219116\n",
      "validation losses average:  tensor(0.00199155, grad_fn=<DivBackward0>)\n",
      "epoch: 100 gamma 2.7318619677157453e-07 lambda: 2.953045129776001\n",
      "MSE loss:  0.0016251100460067391 , Norm of product: tensor(227.96835327)\n",
      "epoch: 110 gamma 2.98779720109723e-07 lambda: 2.8742623329162598\n",
      "validation losses average:  tensor(0.00470420, grad_fn=<DivBackward0>)\n",
      "epoch: 110 gamma 3.017675173108202e-07 lambda: 2.8656394481658936\n",
      "MSE loss:  0.003480224870145321 , Norm of product: tensor(196.16975403)\n",
      "epoch: 120 gamma 3.3003868945736705e-07 lambda: 2.7891886234283447\n",
      "validation losses average:  tensor(0.01125475, grad_fn=<DivBackward0>)\n",
      "epoch: 120 gamma 3.3333907635194074e-07 lambda: 2.7808210849761963\n",
      "MSE loss:  0.013416116125881672 , Norm of product: tensor(168.80656433)\n",
      "epoch: 130 gamma 3.645680386163254e-07 lambda: 2.7066333293914795\n",
      "validation losses average:  tensor(0.01330657, grad_fn=<DivBackward0>)\n",
      "epoch: 130 gamma 3.6821371900248867e-07 lambda: 2.6985132694244385\n",
      "MSE loss:  0.00905743520706892 , Norm of product: tensor(145.26046753)\n",
      "epoch: 140 gamma 4.027099216733594e-07 lambda: 2.626520872116089\n",
      "validation losses average:  tensor(0.01571791, grad_fn=<DivBackward0>)\n",
      "epoch: 140 gamma 4.0673702089009297e-07 lambda: 2.6186411380767822\n",
      "MSE loss:  0.012341533787548542 , Norm of product: tensor(124.99838257)\n",
      "epoch: 150 gamma 4.44842289603006e-07 lambda: 2.5487794876098633\n",
      "validation losses average:  tensor(0.02470470, grad_fn=<DivBackward0>)\n",
      "epoch: 150 gamma 4.4929071249903604e-07 lambda: 2.541133165359497\n",
      "MSE loss:  0.01852375641465187 , Norm of product: tensor(107.56253052)\n",
      "epoch: 160 gamma 4.913826354140591e-07 lambda: 2.473339557647705\n",
      "validation losses average:  tensor(0.03600150, grad_fn=<DivBackward0>)\n",
      "epoch: 160 gamma 4.962964617681997e-07 lambda: 2.4659194946289062\n",
      "MSE loss:  0.03692781552672386 , Norm of product: tensor(92.55897522)\n",
      "epoch: 170 gamma 5.427921311212372e-07 lambda: 2.400132417678833\n",
      "validation losses average:  tensor(0.04954840, grad_fn=<DivBackward0>)\n",
      "epoch: 170 gamma 5.482200524324495e-07 lambda: 2.3929319381713867\n",
      "MSE loss:  0.05618751049041748 , Norm of product: tensor(79.64824677)\n",
      "epoch: 180 gamma 5.995801975356182e-07 lambda: 2.329092264175415\n",
      "validation losses average:  tensor(0.06028900, grad_fn=<DivBackward0>)\n",
      "epoch: 180 gamma 6.055759995109744e-07 lambda: 2.3221049308776855\n",
      "MSE loss:  0.04913480952382088 , Norm of product: tensor(68.53829193)\n",
      "epoch: 190 gamma 6.623095521562643e-07 lambda: 2.260154962539673\n",
      "validation losses average:  tensor(0.06609517, grad_fn=<DivBackward0>)\n",
      "epoch: 190 gamma 6.689326476778269e-07 lambda: 2.2533743381500244\n",
      "MSE loss:  0.04980482533574104 , Norm of product: tensor(58.97821808)\n",
      "epoch: 200 gamma 7.316017851829957e-07 lambda: 2.193258047103882\n",
      "validation losses average:  tensor(0.07698196, grad_fn=<DivBackward0>)\n",
      "epoch: 200 gamma 7.389178030348257e-07 lambda: 2.186678171157837\n",
      "MSE loss:  0.059361882507801056 , Norm of product: tensor(50.75150299)\n",
      "epoch: 210 gamma 8.081435189034723e-07 lambda: 2.1283411979675293\n",
      "validation losses average:  tensor(0.08361843, grad_fn=<DivBackward0>)\n",
      "epoch: 210 gamma 8.16224954092507e-07 lambda: 2.1219561100006104\n",
      "MSE loss:  0.057644009590148926 , Norm of product: tensor(43.67232513)\n",
      "epoch: 220 gamma 8.926932114884434e-07 lambda: 2.065345525741577\n",
      "validation losses average:  tensor(0.08687096, grad_fn=<DivBackward0>)\n",
      "epoch: 220 gamma 9.016201436033279e-07 lambda: 2.0591495037078857\n",
      "MSE loss:  0.09694495797157288 , Norm of product: tensor(37.58060455)\n",
      "epoch: 230 gamma 9.860886726145183e-07 lambda: 2.0042145252227783\n",
      "validation losses average:  tensor(0.09786376, grad_fn=<DivBackward0>)\n",
      "epoch: 230 gamma 9.959495593406635e-07 lambda: 1.998201847076416\n",
      "MSE loss:  0.09752410650253296 , Norm of product: tensor(32.33859253)\n",
      "epoch: 240 gamma 1.0892553653873624e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09850175, grad_fn=<DivBackward0>)\n",
      "epoch: 240 gamma 1.100147919041236e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.12256192415952682 , Norm of product: tensor(31.85640907)\n",
      "epoch: 250 gamma 1.2032155768297464e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09784112, grad_fn=<DivBackward0>)\n",
      "epoch: 250 gamma 1.215247732598044e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.11087616533041 , Norm of product: tensor(31.85642242)\n",
      "epoch: 260 gamma 1.329098547805543e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09687401, grad_fn=<DivBackward0>)\n",
      "epoch: 260 gamma 1.3423895332835984e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.08115945756435394 , Norm of product: tensor(31.85637665)\n",
      "epoch: 270 gamma 1.4681516627579043e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09618546, grad_fn=<DivBackward0>)\n",
      "epoch: 270 gamma 1.4828331793854834e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.09506624937057495 , Norm of product: tensor(31.85641098)\n",
      "epoch: 280 gamma 1.6217528101416305e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09565343, grad_fn=<DivBackward0>)\n",
      "epoch: 280 gamma 1.6379703382430468e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.09174919873476028 , Norm of product: tensor(31.85637474)\n",
      "epoch: 290 gamma 1.7914240360302415e-06 lambda: 1.998201847076416\n",
      "validation losses average:  tensor(0.09560959, grad_fn=<DivBackward0>)\n",
      "epoch: 290 gamma 1.809338276390544e-06 lambda: 1.998201847076416\n",
      "MSE loss:  0.08069019764661789 , Norm of product: tensor(31.85637856)\n"
     ]
    }
   ],
   "source": [
    "gammaScheduler = 1.01\n",
    "gammaStopThreshold = 1e-5\n",
    "lambdaVal = torch.Tensor([4.]).to(device)\n",
    "minimumLambda = 2\n",
    "lambdaScheduler = 0.997\n",
    "net.train()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "if checkpointResume:\n",
    "    checkpointDictionary = torch.load(\"checkpoint.pth\")\n",
    "    optimizer.load_state_dict(checkpointDictionary[\"optimizerStateDict\"])\n",
    "    scheduler.load_state_dict(checkpointDictionary[\"schedulerState\"])\n",
    "    net.load_state_dict(checkpointDictionary[\"networkStateDict\"])\n",
    "    bestStateDict = checkpointDictionary[\"bestStateDict\"]\n",
    "    bestLoss = checkpointDictionary[\"bestLoss\"]\n",
    "    trainLosses = checkpointDictionary['trainLosses']\n",
    "    validationLosses = checkpointDictionary['validationLosses']\n",
    "    gamma = checkpointDictionary['gamma']\n",
    "    trainset = checkpointDictionary['trainSet']\n",
    "    testSet = checkpointDictionary['testSet']\n",
    "\n",
    "\n",
    "    # epoch = checkpointDictionary['maxEpoch']\n",
    "    startingEpoch = checkpointDictionary['epoch']\n",
    "    epoch = 1000\n",
    "else:\n",
    "\n",
    "    trainset, testSet = torch.utils.data.random_split(torch.utils.data.TensorDataset(torch.Tensor(XFull), torch.Tensor(YFull)), [trainSize, XFull.shape[0] - trainSize])\n",
    "    startingEpoch = 0\n",
    "    epoch = 300\n",
    "    trainLosses = []\n",
    "    validationLosses = []\n",
    "    gamma = 1e-7\n",
    "    # gamma = 0\n",
    "    bestStateDict = None\n",
    "    bestLoss = 100000\n",
    "    criterion = my_loss\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=train_batch_size, num_workers=2)\n",
    "loaders = {\"train\": trainloader, \"eval\": testLoader}\n",
    "\n",
    "\n",
    "for t in range(startingEpoch, epoch):\n",
    "    for phase in {\"train\", 'eval'}:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        tempValidationLosses = []\n",
    "        for i, (X, Y) in enumerate(loaders[phase]):\n",
    "\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            out = net(X)\n",
    "            loss = criterion(out, Y)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    for j in range(numberOfLayers):\n",
    "                        net[2 * j].weight /= torch.maximum(torch.tensor([1.]).to(device), (torch.linalg.norm(net[2 * j].weight) / lambdaVal))\n",
    "            else:\n",
    "                tempValidationLosses.append(loss)\n",
    "                if loss < bestLoss:\n",
    "                    bestLoss = loss\n",
    "                    bestStateDict = net.state_dict()\n",
    "                    torch.save(bestStateDic, \"tempBestStateDict.pth\")\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "            # if gamma > gammaStopThreshold:\n",
    "            if gamma < gammaStopThreshold:\n",
    "                gamma *= gammaScheduler\n",
    "            if lambdaVal > minimumLambda:\n",
    "                lambdaVal *= lambdaScheduler\n",
    "            trainLosses.append(loss.item())\n",
    "            checkpointDictionary = \\\n",
    "                {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "                \"schedulerState\": scheduler.state_dict(),\n",
    "                 \"networkStateDict\": net.state_dict(),\n",
    "                 \"bestStateDict\": bestStateDic,\n",
    "                 \"bestLoss\": bestLoss,\n",
    "                 \"trainLosses\": trainLosses,\n",
    "                 \"validationLosses\": validationLosses,\n",
    "                 \"epoch\": t,\n",
    "                 \"maxEpoch\": epoch,\n",
    "                 \"gamma\": gamma,\n",
    "                 \"trainSet\": trainset,\n",
    "                 \"testSet\": testSet}\n",
    "            torch.save(checkpointDictionary, \"checkpoint.pth\")\n",
    "        else:\n",
    "            validationLosses.append(sum(tempValidationLosses[:-1]) / (len(tempValidationLosses) - 1))\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"epoch:\", t, \"gamma\", gamma, \"lambda:\", lambdaVal.item())\n",
    "            if phase == \"train\":\n",
    "                with torch.no_grad():\n",
    "                    prod = torch.linalg.norm(net[0].weight)\n",
    "                    for i in range(1, numberOfLayers):\n",
    "                        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "                    print('MSE loss: ', loss.item(), \", Norm of product:\", prod)\n",
    "            else:\n",
    "                print(\"validation losses average: \", validationLosses[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "checkpointDictionary = \\\n",
    "    {\"optimizerStateDict\": optimizer.state_dict(),\n",
    "    \"schedulerState\": scheduler.state_dict(),\n",
    "     \"networkStateDict\": net.state_dict(),\n",
    "     \"bestStateDict\": bestStateDict,\n",
    "     \"bestLoss\": bestLoss,\n",
    "     \"trainLosses\": trainLosses,\n",
    "     \"validationLosses\": validationLosses,\n",
    "     \"epoch\": t,\n",
    "     \"maxEpoch\": epoch,\n",
    "     \"gamma\": gamma,\n",
    "     \"trainSet\": trainset,\n",
    "     \"testSet\": testSet}\n",
    "torch.save(checkpointDictionary, \"checkpoint.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.48641037940979, 4.712788343429565, 4.482716822624207, 4.7129652261734005)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 6\n",
    "device = torch.device(\"cpu\")\n",
    "net.to(device)\n",
    "lowerCoordinate = torch.Tensor([4.6975, 4.6975, 2.9975, 0.9499, -0.0001, -0.0001]).to(device)\n",
    "upperCoordinate = torch.Tensor([4.7025, 4.7025 ,3.0025, 0.9501,  0.0001,  0.0001 ]).to(device)\n",
    "inputData = (upperCoordinate - lowerCoordinate) * torch.rand(1000, dim, device=device) \\\n",
    "                                                        + lowerCoordinate\n",
    "plt.scatter(inputData[:, 0], inputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "outputData = net(inputData).detach().cpu().numpy()\n",
    "if lastDim == 3:\n",
    "    outputData = (A @ inputData.detach().cpu().numpy().T + B @ outputData.T + C).T\n",
    "plt.scatter(outputData[:, 0], outputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "plt.axis(\"equal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 6])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "lastDim = 6\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"tempBestStateDict.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainCompleteLoop = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss:  tensor(5.85772032e-05, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDict)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.9.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.6.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDic)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.1.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11457, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}