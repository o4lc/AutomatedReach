{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`polytope` failed to import `cvxopt.glpk`.\n",
      "will use `scipy.optimize.linprog`\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  1 17:45:41 2020\n",
    "\n",
    "@author: mahyarfazlyab\n",
    "\"\"\"\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"../Python/\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import loadmat\n",
    "import scipy.io\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "\n",
    "\n",
    "\n",
    "def export2matlab(file_name, net, A, B, save_model=False):\n",
    "    '''\n",
    "    Export pytorch fully connected network to matlab\n",
    "\n",
    "    '''\n",
    "\n",
    "    num_layers = int((len(net) - 1) / 2)\n",
    "    dim_in = float(net[0].weight.shape[1])\n",
    "    dim_out = float(net[-1].weight.shape[0])\n",
    "    hidden_dims = [float(net[2 * i].weight.shape[0]) for i in range(0, num_layers)]\n",
    "\n",
    "    # network dimensions\n",
    "    dims = [dim_in] + hidden_dims + [dim_out]\n",
    "\n",
    "    # get weights\n",
    "    # weights = np.zeros((num_layers+1,))\n",
    "    weights = [net[2 * i].weight.detach().numpy().astype(np.float64) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    # get biases\n",
    "    # biases = np.zeros((num_layers+1,))\n",
    "    biases = [net[2 * i].bias.detach().numpy().astype(np.float64).reshape(-1, 1) for i in range(0, num_layers + 1)]\n",
    "\n",
    "    activation = str(net[1])[0:-2].lower()\n",
    "\n",
    "    # export network data to matlab\n",
    "    data = {}\n",
    "    data['net'] = {'weights': weights, 'biases': biases, 'dims': dims, 'activation': activation, 'name': file_name}\n",
    "    data['AMatrix'] = A\n",
    "    data['BMatrix'] = B\n",
    "\n",
    "\n",
    "    scipy.io.savemat(file_name + '.mat', data)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 gamma 1\n",
      "validation losses average:  tensor(133.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 0 gamma 0.9\n",
      "MSE loss:  12.071584701538086 , Norm of product: tensor(7.2511, device='cuda:0')\n",
      "epoch: 10 gamma 0.34867844010000015\n",
      "validation losses average:  tensor(4.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 10 gamma 0.31381059609000017\n",
      "MSE loss:  4.203967571258545 , Norm of product: tensor(0.0150, device='cuda:0')\n",
      "epoch: 20 gamma 0.12157665459056936\n",
      "validation losses average:  tensor(4.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 20 gamma 0.10941898913151243\n",
      "MSE loss:  4.389400959014893 , Norm of product: tensor(0.0001, device='cuda:0')\n",
      "epoch: 30 gamma 0.042391158275216244\n",
      "validation losses average:  tensor(4.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 30 gamma 0.03815204244769462\n",
      "MSE loss:  3.9314870834350586 , Norm of product: tensor(0.0012, device='cuda:0')\n",
      "epoch: 40 gamma 0.014780882941434608\n",
      "validation losses average:  tensor(0.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 40 gamma 0.013302794647291147\n",
      "MSE loss:  0.5138154625892639 , Norm of product: tensor(23.8516, device='cuda:0')\n",
      "epoch: 50 gamma 0.00515377520732012\n",
      "validation losses average:  tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 50 gamma 0.004638397686588107\n",
      "MSE loss:  0.23376180231571198 , Norm of product: tensor(19.6007, device='cuda:0')\n",
      "epoch: 60 gamma 0.0017970102999144335\n",
      "validation losses average:  tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 60 gamma 0.0016173092699229901\n",
      "MSE loss:  0.1517244428396225 , Norm of product: tensor(19.1602, device='cuda:0')\n",
      "epoch: 70 gamma 0.0006265787482177979\n",
      "validation losses average:  tensor(0.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 70 gamma 0.0005639208733960181\n",
      "MSE loss:  0.1276707649230957 , Norm of product: tensor(19.7634, device='cuda:0')\n",
      "epoch: 80 gamma 0.00021847450052839252\n",
      "validation losses average:  tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 80 gamma 0.00019662705047555326\n",
      "MSE loss:  0.11059825867414474 , Norm of product: tensor(20.8917, device='cuda:0')\n",
      "epoch: 90 gamma 7.617734804586655e-05\n",
      "validation losses average:  tensor(0.1171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 90 gamma 6.85596132412799e-05\n",
      "MSE loss:  0.09830795973539352 , Norm of product: tensor(22.2776, device='cuda:0')\n",
      "epoch: 100 gamma 2.6561398887587544e-05\n",
      "validation losses average:  tensor(0.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 100 gamma 2.390525899882879e-05\n",
      "MSE loss:  0.11236047744750977 , Norm of product: tensor(23.6476, device='cuda:0')\n",
      "epoch: 110 gamma 9.261387130997904e-06\n",
      "validation losses average:  tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 110 gamma 8.335248417898115e-06\n",
      "MSE loss:  0.10654715448617935 , Norm of product: tensor(25.2536, device='cuda:0')\n",
      "epoch: 120 gamma 3.229246017998565e-06\n",
      "validation losses average:  tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 120 gamma 2.9063214161987086e-06\n",
      "MSE loss:  0.095345638692379 , Norm of product: tensor(32.1546, device='cuda:0')\n",
      "epoch: 130 gamma 1.1259684642548765e-06\n",
      "validation losses average:  tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 130 gamma 1.0133716178293888e-06\n",
      "MSE loss:  0.06138243153691292 , Norm of product: tensor(38.0436, device='cuda:0')\n",
      "epoch: 140 gamma 3.92600927718183e-07\n",
      "validation losses average:  tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 140 gamma 3.5334083494636473e-07\n",
      "MSE loss:  0.06861955672502518 , Norm of product: tensor(38.8085, device='cuda:0')\n",
      "epoch: 150 gamma 1.3689147905858892e-07\n",
      "validation losses average:  tensor(0.0758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 150 gamma 1.2320233115273002e-07\n",
      "MSE loss:  0.07033328711986542 , Norm of product: tensor(39.7519, device='cuda:0')\n",
      "epoch: 160 gamma 4.7731107381130604e-08\n",
      "validation losses average:  tensor(0.0729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 160 gamma 4.295799664301754e-08\n",
      "MSE loss:  0.061708852648735046 , Norm of product: tensor(41.8478, device='cuda:0')\n",
      "epoch: 170 gamma 1.6642808065898218e-08\n",
      "validation losses average:  tensor(0.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 170 gamma 1.4978527259308396e-08\n",
      "MSE loss:  0.04152911901473999 , Norm of product: tensor(49.1499, device='cuda:0')\n",
      "epoch: 180 gamma 5.80298835530109e-09\n",
      "validation losses average:  tensor(0.0372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 180 gamma 5.222689519770981e-09\n",
      "MSE loss:  0.03903229907155037 , Norm of product: tensor(54.5321, device='cuda:0')\n",
      "epoch: 190 gamma 2.0233769276448487e-09\n",
      "validation losses average:  tensor(0.0367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 190 gamma 1.821039234880364e-09\n",
      "MSE loss:  0.0346316322684288 , Norm of product: tensor(55.3704, device='cuda:0')\n",
      "epoch: 200 gamma 7.055079108655365e-10\n",
      "validation losses average:  tensor(0.0362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 200 gamma 6.349571197789829e-10\n",
      "MSE loss:  0.04873505234718323 , Norm of product: tensor(56.1301, device='cuda:0')\n",
      "epoch: 210 gamma 2.4599539783880517e-10\n",
      "validation losses average:  tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 210 gamma 2.2139585805492464e-10\n",
      "MSE loss:  0.031852949410676956 , Norm of product: tensor(57.0609, device='cuda:0')\n",
      "epoch: 220 gamma 8.577329159021353e-11\n",
      "validation losses average:  tensor(0.0344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 220 gamma 7.719596243119218e-11\n",
      "MSE loss:  0.04209600389003754 , Norm of product: tensor(58.1124, device='cuda:0')\n",
      "epoch: 230 gamma 2.9907297513918106e-11\n",
      "validation losses average:  tensor(0.0330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 230 gamma 2.6916567762526297e-11\n",
      "MSE loss:  0.03295423835515976 , Norm of product: tensor(59.2283, device='cuda:0')\n",
      "epoch: 240 gamma 1.0428029844759576e-11\n",
      "validation losses average:  tensor(0.0311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 240 gamma 9.38522686028362e-12\n",
      "MSE loss:  0.026354225352406502 , Norm of product: tensor(60.3661, device='cuda:0')\n",
      "epoch: 250 gamma 3.6360291795870155e-12\n",
      "validation losses average:  tensor(0.0290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 250 gamma 3.272426261628314e-12\n",
      "MSE loss:  0.026316940784454346 , Norm of product: tensor(61.4693, device='cuda:0')\n",
      "epoch: 260 gamma 1.2678049824964836e-12\n",
      "validation losses average:  tensor(0.0268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 260 gamma 1.1410244842468353e-12\n",
      "MSE loss:  0.0273746307939291 , Norm of product: tensor(62.4865, device='cuda:0')\n",
      "epoch: 270 gamma 4.4205626364788173e-13\n",
      "validation losses average:  tensor(0.0246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 270 gamma 3.9785063728309357e-13\n",
      "MSE loss:  0.03127012029290199 , Norm of product: tensor(63.4010, device='cuda:0')\n",
      "epoch: 280 gamma 1.541354884451778e-13\n",
      "validation losses average:  tensor(0.0225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 280 gamma 1.3872193960066002e-13\n",
      "MSE loss:  0.02284700609743595 , Norm of product: tensor(64.1957, device='cuda:0')\n",
      "epoch: 290 gamma 5.374372167511618e-14\n",
      "validation losses average:  tensor(0.0207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 290 gamma 4.836934950760456e-14\n",
      "MSE loss:  0.018601685762405396 , Norm of product: tensor(64.8762, device='cuda:0')\n",
      "epoch: 300 gamma 1.8739277038848075e-14\n",
      "validation losses average:  tensor(0.0192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 300 gamma 1.6865349334963268e-14\n",
      "MSE loss:  0.02153787575662136 , Norm of product: tensor(65.4520, device='cuda:0')\n",
      "epoch: 310 gamma 6.5339818865072964e-15\n",
      "validation losses average:  tensor(0.0179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 310 gamma 5.880583697856567e-15\n",
      "MSE loss:  0.019040316343307495 , Norm of product: tensor(65.9395, device='cuda:0')\n",
      "epoch: 320 gamma 2.2782586118290197e-15\n",
      "validation losses average:  tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 320 gamma 2.0504327506461177e-15\n",
      "MSE loss:  0.01420401968061924 , Norm of product: tensor(66.3433, device='cuda:0')\n",
      "epoch: 330 gamma 7.943796589169342e-16\n",
      "validation losses average:  tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 330 gamma 7.149416930252408e-16\n",
      "MSE loss:  0.014217674732208252 , Norm of product: tensor(66.6793, device='cuda:0')\n",
      "epoch: 340 gamma 2.7698306031832673e-16\n",
      "validation losses average:  tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 340 gamma 2.4928475428649406e-16\n",
      "MSE loss:  0.012306435033679008 , Norm of product: tensor(66.9578, device='cuda:0')\n",
      "epoch: 350 gamma 9.65780214059184e-17\n",
      "validation losses average:  tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 350 gamma 8.692021926532657e-17\n",
      "MSE loss:  0.016767330467700958 , Norm of product: tensor(67.1885, device='cuda:0')\n",
      "epoch: 360 gamma 3.367467385176005e-17\n",
      "validation losses average:  tensor(0.0140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 360 gamma 3.0307206466584045e-17\n",
      "MSE loss:  0.016932105645537376 , Norm of product: tensor(67.3777, device='cuda:0')\n",
      "epoch: 370 gamma 1.1741632749507956e-17\n",
      "validation losses average:  tensor(0.0136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 370 gamma 1.0567469474557161e-17\n",
      "MSE loss:  0.014849558472633362 , Norm of product: tensor(67.5321, device='cuda:0')\n",
      "epoch: 380 gamma 4.09405419132551e-18\n",
      "validation losses average:  tensor(0.0133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 380 gamma 3.6846487721929585e-18\n",
      "MSE loss:  0.011599907651543617 , Norm of product: tensor(67.6620, device='cuda:0')\n",
      "epoch: 390 gamma 1.4275084291162459e-18\n",
      "validation losses average:  tensor(0.0130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 390 gamma 1.2847575862046213e-18\n",
      "MSE loss:  0.012095811776816845 , Norm of product: tensor(67.7679, device='cuda:0')\n",
      "epoch: 400 gamma 4.977414122938543e-19\n",
      "validation losses average:  tensor(0.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 400 gamma 4.479672710644689e-19\n",
      "MSE loss:  0.013186758384108543 , Norm of product: tensor(67.8550, device='cuda:0')\n",
      "epoch: 410 gamma 1.7355169921179214e-19\n",
      "validation losses average:  tensor(0.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 410 gamma 1.5619652929061291e-19\n",
      "MSE loss:  0.01342108566313982 , Norm of product: tensor(67.9263, device='cuda:0')\n",
      "epoch: 420 gamma 6.051373575787208e-20\n",
      "validation losses average:  tensor(0.0124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 420 gamma 5.446236218208488e-20\n",
      "MSE loss:  0.011256462894380093 , Norm of product: tensor(67.9838, device='cuda:0')\n",
      "epoch: 430 gamma 2.1099834988678436e-20\n",
      "validation losses average:  tensor(0.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 430 gamma 1.8989851489810592e-20\n",
      "MSE loss:  0.011020015925168991 , Norm of product: tensor(68.0309, device='cuda:0')\n",
      "epoch: 440 gamma 7.3570575502198e-21\n",
      "validation losses average:  tensor(0.0122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 440 gamma 6.62135179519782e-21\n",
      "MSE loss:  0.015030436217784882 , Norm of product: tensor(68.0716, device='cuda:0')\n",
      "epoch: 450 gamma 2.565247350336568e-21\n",
      "validation losses average:  tensor(0.0121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "epoch: 450 gamma 2.3087226153029112e-21\n",
      "MSE loss:  0.013228368945419788 , Norm of product: tensor(68.1042, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 97\u001B[0m\n\u001B[1;32m     95\u001B[0m     net\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     96\u001B[0m tempValidationLosses \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (X, Y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loaders[phase]):\n\u001B[1;32m     99\u001B[0m     X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    100\u001B[0m     Y \u001B[38;5;241m=\u001B[39m Y\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[0;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1196\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1194\u001B[0m     \u001B[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001B[39;00m\n\u001B[1;32m   1195\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent_workers:\n\u001B[0;32m-> 1196\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shutdown_workers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1197\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1199\u001B[0m \u001B[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001B[39;00m\n\u001B[1;32m   1200\u001B[0m \n\u001B[1;32m   1201\u001B[0m \u001B[38;5;66;03m# Check if the next sample has already been generated\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1322\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1317\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mark_worker_as_unavailable(worker_id, shutdown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers:\n\u001B[1;32m   1319\u001B[0m     \u001B[38;5;66;03m# We should be able to join here, but in case anything went\u001B[39;00m\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001B[39;00m\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;66;03m# they are killed in the `finally` block.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m     \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMP_STATUS_CHECK_INTERVAL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues:\n\u001B[1;32m   1324\u001B[0m     q\u001B[38;5;241m.\u001B[39mcancel_join_thread()\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/process.py:149\u001B[0m, in \u001B[0;36mBaseProcess.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_pid \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a child process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a started process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 149\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_popen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m     _children\u001B[38;5;241m.\u001B[39mdiscard(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/popen_fork.py:44\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconnection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wait\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m/usr/lib/python3.8/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainCompleteLoop = True\n",
    "# with open('xs.pkl', 'rb') as f:\n",
    "#     Xtrain = pickle.load(f)\n",
    "#\n",
    "# with open('us.pkl', 'rb') as f:\n",
    "#     Ytrain = pickle.load(f)\n",
    "\n",
    "data = loadmat(\"trainDataQuad.mat\")\n",
    "XFull = data['X']\n",
    "YFull = data['y']\n",
    "# data = loadmat(\"quadRotorTrainData.mat\")\n",
    "# Xtrain = data['Xtrain']\n",
    "# Ytrain = data['Ytrain']\n",
    "# A = data['A']\n",
    "# B = data['B']\n",
    "if True:\n",
    "    A = np.zeros((6, 6), dtype=np.float32)\n",
    "    A[0, 3] = 1.\n",
    "    A[1, 4] = 1\n",
    "    A[2, 5] = 1\n",
    "\n",
    "    B = np.zeros((6, 3), dtype=np.float32)\n",
    "    B[3, 0] =  9.8\n",
    "    B[4, 1] = -9.8\n",
    "    B[5, 2] =  1\n",
    "\n",
    "    C = np.zeros((6, 1), dtype=np.float32)\n",
    "    C[5] = -9.8\n",
    "\n",
    "    A = np.eye(6) + A * 0.1\n",
    "    B = B * 0.1\n",
    "    C = C * 0.1\n",
    "\n",
    "else:\n",
    "    A = np.array([[1, 1], [0, 1]])\n",
    "    B = np.array([[0.5], [1]])\n",
    "lastDim = 3\n",
    "if trainCompleteLoop:\n",
    "    YFull = (A @ XFull.T + B @ YFull.T + C).T\n",
    "    lastDim = 6\n",
    "\n",
    "# print(torch.linalg.norm(torch.Tensor(B)), torch.linalg.norm(torch.Tensor(A)))\n",
    "# raise\n",
    "# print(A)\n",
    "# print(B)\n",
    "# print(Xtrain.shape)\n",
    "# print(Ytrain.shape)\n",
    "dataSplit = 0.9\n",
    "trainSize = int(dataSplit * XFull.shape[0])\n",
    "\n",
    "trainset, testSet = torch.utils.data.random_split(torch.utils.data.TensorDataset(torch.Tensor(XFull), torch.Tensor(YFull)), [trainSize, XFull.shape[0] - trainSize])\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "numberOfLayers = (len(net) + 1) // 2\n",
    "net.to(device)\n",
    "train_batch_size = 128\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True,\n",
    "                                          num_workers=2)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, batch_size=train_batch_size, num_workers=2)\n",
    "epoch = 1000\n",
    "net.train()\n",
    "trainLosses = []\n",
    "validationLosses = []\n",
    "gamma = 1\n",
    "def my_loss(output, target):\n",
    "    prod = torch.linalg.norm(net[0].weight)\n",
    "    for i in range(1, numberOfLayers):\n",
    "        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "    loss = torch.mean((output - target)**2) + gamma * prod\n",
    "    return loss\n",
    "bestStateDic = None\n",
    "bestLoss = 100000\n",
    "criterion = my_loss\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "\n",
    "lambdaVal = torch.Tensor([2]).to(device)\n",
    "loaders = {\"train\": trainloader, \"eval\": testLoader}\n",
    "for t in range(epoch):\n",
    "    for phase in {\"train\", 'eval'}:\n",
    "        if phase == \"train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        tempValidationLosses = []\n",
    "        for i, (X, Y) in enumerate(loaders[phase]):\n",
    "\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            out = net(X)\n",
    "            loss = criterion(out, Y)\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    optimizer.zero_grad()\n",
    "                    # for i in [0, 2, 4]:\n",
    "                    #     net[i].weight /= torch.maximum(torch.tensor([1.]).to(device), (torch.linalg.norm(net[i].weight) / lambdaVal))\n",
    "            else:\n",
    "                tempValidationLosses.append(loss)\n",
    "                if loss < bestLoss:\n",
    "                    bestLoss = loss\n",
    "                    bestStateDic = net.state_dict()\n",
    "                    torch.save(bestStateDic, \"tempBestStateDict.pth\")\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "            gamma *= 0.9\n",
    "            trainLosses.append(loss.item())\n",
    "        else:\n",
    "            validationLosses.append(sum(tempValidationLosses[:-1]) / (len(tempValidationLosses) - 1))\n",
    "        if np.mod(t, 10) == 0:\n",
    "            print(\"epoch:\", t, \"gamma\", gamma)\n",
    "            if phase == \"train\":\n",
    "                with torch.no_grad():\n",
    "                    prod = torch.linalg.norm(net[0].weight)\n",
    "                    for i in range(1, numberOfLayers):\n",
    "                        prod *= torch.linalg.norm(net[2 * i].weight)\n",
    "                    print('MSE loss: ', loss.item(), \", Norm of product:\", prod)\n",
    "            else:\n",
    "                print(\"validation losses average: \", validationLosses[-1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(4.695100736618042, 4.74815182685852, 4.672193026542663, 4.703937554359436)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/R0lEQVR4nO3de3xU5YH/8e+ZSyYXkgmJJJnECJGLsIasBVca4VdtCaK/bAtb15Y2FkWtFlMNdFeRbhGtSFB+VUrdCrLoWm+8VtdatvKCIlYsC0Iamgpt5SKXhEtADMnkQibJzPn9MTIyECCT2yTHz/v1Oi+SM895znMOvJyvz3nO8ximaZoCAADo52zRbgAAAEB3INQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLcES7Ab0lEAjoyJEjSkxMlGEY0W4OAADoANM0VV9fr8zMTNlsF+6L+cKEmiNHjig7OzvazQAAAJ1QVVWlSy+99IJlvjChJjExUVLwpiQlJUW5NQAAoCO8Xq+ys7ND3+MX8oUJNacfOSUlJRFqAADoZzoydISBwgAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBK6FGoWLVokwzA0a9as85a5/vrrZRjGOVthYWGojGmaevjhh+XxeBQXF6eCggLt2bMnrJ4hQ4acU8eiRYu60nwAAGAhnQ41ZWVlWr58ufLy8i5Y7s0339TRo0dD286dO2W323XLLbeEyjz55JNaunSpli1bpq1btyohIUGTJ09Wc3NzWF0//elPw+q67777Ott8AABgMZ0KNQ0NDSoqKtKKFSs0cODAC5ZNSUlRRkZGaFu/fr3i4+NDocY0TS1ZskQ/+clPNGXKFOXl5elXv/qVjhw5orfeeiusrsTExLC6EhISOtN8AABgQZ0KNcXFxSosLFRBQUHEx65cuVLTpk0LBZL9+/eruro6rC63261x48Zpy5YtYccuWrRIqamp+tKXvqTFixerra3tvOfx+Xzyer1hGwAAsC5HpAesWrVK27dvV1lZWcQn27Ztm3bu3KmVK1eG9lVXV0uS0tPTw8qmp6eHPpOk+++/X2PGjFFKSoo2b96suXPn6ujRo3rqqafaPVdpaakeffTRiNsIAAD6p4hCTVVVlUpKSrR+/XrFxsZGfLKVK1dq9OjRuuaaayI+9kc/+lHo57y8PMXExOiee+5RaWmpXC7XOeXnzp0bdozX61V2dnbE5wUAAP1DRI+fysvLdfz4cY0ZM0YOh0MOh0MbN27U0qVL5XA45Pf7z3tsY2OjVq1apTvvvDNsf0ZGhiTp2LFjYfuPHTsW+qw948aNU1tbmw4cONDu5y6XS0lJSWEbAACwrohCzcSJE7Vjxw5VVFSEtquvvlpFRUWqqKiQ3W4/77Gvv/66fD6fbr311rD9OTk5ysjI0IYNG0L7vF6vtm7dqvz8/PPWV1FRIZvNprS0tEguAQAAWFREj58SExOVm5sbti8hIUGpqamh/dOnT1dWVpZKS0vDyq1cuVJTp05Vampq2P7T89wsWLBAw4cPV05OjubNm6fMzExNnTpVkrRlyxZt3bpVX/3qV5WYmKgtW7Zo9uzZuvXWWy/69hUAAPhiiHig8MVUVlbKZgvvANq1a5c2bdqk3/3ud+0e8+CDD6qxsVF33323amtrNWHCBK1duzY0bsflcmnVqlV65JFH5PP5lJOTo9mzZ4eNmQEAAF9shmmaZrQb0Ru8Xq/cbrfq6uoYXwMAQD8Ryfc3az8BAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLINQAAABLcES7AVZQ39yq2qZWJcc71dDcpo+qvXLYDA1KjFXWwLjQvqRYpzKT41R7qkVNPr8aW1rlD0gjM5LkSY4L1XX45CmZMnXpwHglxjpD+w+dbJIhQ1kD40L723O09pQqa5qUmhCjtoApU6aS44I/J8c7L3gsAAD9FaGmi3YertPr5VWqa2rVpw0+7f2kUSebWtTmDyg5LkaZ7lgd9TarqaVNkqG4GLsMSfXNbWoNBOS02ZQ6wKUffm2YRme5tWzjXv3lSL0kU7mZbt1z3VA1+tr07+/t1cfHG+S025SblaQfXDdMuVnuc9qzalulnvvDPtWfatWpVr9i7DbFOGyyGYYyk2M1Ij1R3x03uN1jAQDozwzTNM1oN6I3eL1eud1u1dXVKSkpqVvqrG9u1f/73S7VNLQo0eXU6g8Pq6nFL9OUzr6pTpvkD0gBBZ/5Bc74zJCUGOvQmGy39p1okinJYRgyDWnYoAT99ahXx7w+mabkctg0INah8cNS9YPrhilrYLCH59DJJv1h9yf6xbsfq8Xvl99vqu2sRtgkDXDZlJuVrJ9966pQ7xAAAH1VJN/f9NR0QW1Tq+qaWuVxx+mY95Ra2/wKnCciBs4IOoGzPjMV7LkpO/CpDJtdMk3ZbMEelvLKk6o71Raq91RbQKcaWrT2L9U6dPKUEuMcamz2a/+njappbJE/cG5oCrVBktcX0OZ9NbrjhW2aMeFyjb40KewxFwAA/RWhpguS451yxzv1UbVX+z9pkM9//rL+i/SHmZIaWyXpdCXBWHK+gNLcauqjo/Vq8fvV6g/vGWqv/Nn+dqxBc9/8UImxDl2Vnax/nTySR1IAgH6Nt5+6IDHWqf+b69HRumbVNLXK2QN380IBpaHFrxb/uY+6OspvSrWn2rRx9wn9+M0dqm9u7WRNAABEH6GmizKT43TpwFi5nIb8Heki6YNMSX89Wqc/V9ZGuykAAHQaoaaLkuOdio+xq66prUOPffqqgCkdrT8V7WYAANBphJouOvhpk2oaW887QLi/sBmGRgxKjHYzAADoNEJNF9Q3t+r18iq57IbiemJATS9KiXcqZYAr2s0AAKDT+vc3cZTVNrXq4IlGVZ5sVsCMzsMnRzf9DTa2tMnXeoHXtwAA6OMINV3gsBk6Utusau8pOWyR3cruuvFt3ZSl2gKmDtUypgYA0H8RarqgLWAqJSFGDpshwzBktwVnB+6I7uzXie+OefMCphJdTFsEAOi/CDVdkBzv1OWDEhQf45Cv1S9/oPNzxnRFW6CjUer8Yhx2ZbJsAgCgHyPUdEFirFNTrspSk69NLVF8n7vlYtMVd0BirF1t/f0VLgDAFxqhpot2VdfLe6H1EfqJVr8ph63rPT4AAEQLoaYL6ptbtXbn0Wg3o1t4kuPpqQEA9GuEmi6obWpVrNNmiZvoctqU3C0jjgEAiA4rfB9HTXK8U6kDXOqtpzY9dRpD0pHaU2pobuuhMwAA0PMINV2QGOvUmMtS5OiuGfAuwJB6LDzZDcnX5lfVyaaeOQEAAL2AUNNF118xSFnuODl7uLvGMNRjA3nbTKmlzVRKfEyP1A8AQG8g1HSRJzlO/2f4JerpGWpMUwr04DkGJbrkctp7rH4AAHpal0LNokWLZBiGZs2add4y119/vQzDOGcrLCwMlTFNUw8//LA8Ho/i4uJUUFCgPXv2hNVTU1OjoqIiJSUlKTk5WXfeeacaGhq60vxu8bN1u/Tqtiq19vA8Naakth56c9xhk0akD2CgMACgX+t0qCkrK9Py5cuVl5d3wXJvvvmmjh49Gtp27twpu92uW265JVTmySef1NKlS7Vs2TJt3bpVCQkJmjx5spqbm0NlioqK9Je//EXr16/Xb3/7W73//vu6++67O9v8brH3WL1e3HJArf7em3mvJ4bvpCS4NGN8jhJjCTUAgP6rU1+RDQ0NKioq0ooVKzRw4MALlk1JSVFGRkZoW79+veLj40OhxjRNLVmyRD/5yU80ZcoU5eXl6Ve/+pWOHDmit956S5L0t7/9TWvXrtV//Md/aNy4cZowYYJ+8YtfaNWqVTpy5EhnLqFb/O2oV75Wv4xeevvJVPctYHmm8cNSdE1OavdXDABAL+pUqCkuLlZhYaEKCgoiPnblypWaNm2aEhISJEn79+9XdXV1WF1ut1vjxo3Tli1bJElbtmxRcnKyrr766lCZgoIC2Ww2bd26td3z+Hw+eb3esK27jfIkKcZpl9nOUJf+NDfvbyqO6sE3/hztZgAA0CURh5pVq1Zp+/btKi0tjfhk27Zt086dO3XXXXeF9lVXV0uS0tPTw8qmp6eHPquurlZaWlrY5w6HQykpKaEyZystLZXb7Q5t2dnZEbf3YoalJ+q2/MGyn/FWkiEpxm4o3R3Tb0ZhB0zp1386rD9Xnox2UwAA6LSIvnerqqpUUlKiV155RbGxsRGfbOXKlRo9erSuueaaiI+N1Ny5c1VXVxfaqqqqeuQ891w3VCMzBoRupCnJHzD1aUOLorjGZcRa/aYqDhFqAAD9V0Shpry8XMePH9eYMWPkcDjkcDi0ceNGLV26VA6HQ37/+V/PaWxs1KpVq3TnnXeG7c/IyJAkHTt2LGz/sWPHQp9lZGTo+PHjYZ+3tbWppqYmVOZsLpdLSUlJYVtPOHSySd7mNtmM4CR2kuQ3pdZ+uMZlarwr2k0AAKDTIgo1EydO1I4dO1RRURHarr76ahUVFamiokJ2+/nnOXn99dfl8/l06623hu3PyclRRkaGNmzYENrn9Xq1detW5efnS5Ly8/NVW1ur8vLyUJl3331XgUBA48aNi+QSup0hQ6YpOey2XlsuoSfYDDFrEQCgX3NEUjgxMVG5ublh+xISEpSamhraP336dGVlZZ0z5mblypWaOnWqUlPD37I5Pc/NggULNHz4cOXk5GjevHnKzMzU1KlTJUmjRo3SjTfeqO9///tatmyZWltb9cMf/lDTpk1TZmZmpNfcrbIGxmlQoktHak/J/9mAYUNdm4rPJvX6o6u4GLtGpvdMbxYAAL0holDTEZWVlbLZwv+Xf9euXdq0aZN+97vftXvMgw8+qMbGRt19992qra3VhAkTtHbt2rBxO6+88op++MMfauLEibLZbLr55pu1dOnS7m5+xH774VF9VF0fCjRdZSi4Yvapnp7N7ywThqZqWHpir54TAIDuZJhmey8kW4/X65Xb7VZdXV23ja85WntK313xgSprmmQYkj/weQ/N6SdRkdxcm6S4GJt8bYEemY/mQv5hSLKev/0aJuADAPQpkXx/M4qiCyprmtTU4g8OErbZFHPGkCJTFw80Zw/BCY7JMXs90BiS/na0Xrur63v3xAAAdCNCTRdclhIvd5xTdptNgUAg4vWfzg41babU2NL7HWempEDAVL2vrdfPDQBAdyHUdIEnOU73fnWY0pJcsn326tPpl4jsHXgTqi/NYzMg1qkrGFMDAOjHCDVdNCxtgEZnuRXntMthBB8hBaRuGzjcGxw2Q0MHxWtAbLePGwcAoNcQarqgvrlVyzd+rO0HT6r+VJvaApJhfP5YyWZcfA2ovjC3zSUDYuRyOlTb1BrtpgAA0GmEmi44dLJJ2ytP6mRTi/wK9tC0BT4PMrGO8MHD7Qn0gR6dk40+HTjRKEdfSFgAAHQSoaYLGn1t8p5qVdtZySSg4JgaX1ugT42bOR+/aajB16a6U/TUAAD6L0JNFwxwORUX45BpnvuYyW9+Nq6mD/TEXIxpmjrV4lcjbz8BAPoxQk0XZA2M09BB8ZLOn116eWLgiBnn+RkAgP6GUNNFhmz9oTPmvExJMXabkuOdinfx9hMAoP8i1HTBoZNN+vhEQ794xHQhAZkaneVW1sC4aDcFAIBOI9R0QaOvTU0t/mg3o0sMSf6Aqa+NTGfdJwBAv8bzhi4Y4HIqIcahppa2vjU9cAcluuwKmKZMGUpLckW7OQAAdAk9NV2QNTBOf5c5QA6jfw6xrff5dao1IHccSyQAAPo/Qk0XJMY69YPrhunSlHg5O7LYUx9jSLIbhoakskQCAKD/I9R00TU5qZpX+HcaNMDVoUUsI3WxvyDjrD8jkZ4Yo0x3rBJjnSyRAADo9wg13WBo2gCNzEhURqJL7li7nLbPV+nuSuj4fLkFo92/qAExdn3psmQlxNiVHO+I+Bw2myHDZuiSATFKjmeQMACgf+OZQzdIjncqwx2rfScalWgz1BaQfG1+OQxDibF2xTjs8ja1KCCp1W/KNMPfArdJSnLZ1dDiV5sZ/N1UcLFLu83QkJQBOtbQrPrmVvkDn382+lK3Lhng0uWDEvSPeZn66KhXS97Zrea2c98xd9ok0wyuNRWcm8aQ02HX6Cy3vjtuMG8+AQD6PUJNN0iMdeq74warvrlNO4/U6ZIBLg1OjdWXLx+kqpNN8p5qlc1maPLfZeiTBp9+tfmAak+1qs1vamC8UzEOmy5NiZfDJh33tqj2VIsk6dLkeN1wZZr2f9qknYfq9PGJRjkMyWG3KzslVulJsXLHO3XL2GzlZrl1/RVpGpmRpCfW/k17jzWo1ZRcdmlERpKS42J0oKZRbW2mrsgYoJvHZGt4+gBlDYwj0AAALMEwTbOfTx3XMV6vV263W3V1dUpKSuqRc9Q3t+rwyVOSFAoL9c2tqm1qVXK8MxQejtaeUtXJJqXEx8jltMthM9QWMEOPgM5Xh6/Vr5qmFmUPDA7sPbveM9uxu7pex73NSkuK1YiMxHbrBQCgr4vk+5tQAwAA+qxIvr8ZKAwAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyBUAMAACyhS6Fm0aJFMgxDs2bNumC52tpaFRcXy+PxyOVyacSIEVqzZk3o8/r6es2aNUuDBw9WXFycrr32WpWVlYXVcfvtt8swjLDtxhtv7ErzAQCAhTg6e2BZWZmWL1+uvLy8C5ZraWnRpEmTlJaWpjfeeENZWVk6ePCgkpOTQ2Xuuusu7dy5Uy+99JIyMzP18ssvq6CgQH/961+VlZUVKnfjjTfqhRdeCP3ucrk623wAAGAxnQo1DQ0NKioq0ooVK7RgwYILln3++edVU1OjzZs3y+l0SpKGDBkS+vzUqVP67//+b/3mN7/RV77yFUnSI488ov/5n//Rs88+G1a/y+VSRkZGZ5oMAAAsrlOPn4qLi1VYWKiCgoKLll29erXy8/NVXFys9PR05ebmauHChfL7/ZKktrY2+f1+xcbGhh0XFxenTZs2he177733lJaWpiuuuEIzZ87Up59+2pnmAwAAC4q4p2bVqlXavn37OWNezmffvn169913VVRUpDVr1mjv3r2699571draqvnz5ysxMVH5+fl67LHHNGrUKKWnp+u1117Tli1bNGzYsFA9N954o775zW8qJydHH3/8sX784x/rpptu0pYtW2S32885r8/nk8/nC/3u9XojvVQAANCPRBRqqqqqVFJSovXr15/Ts3I+gUBAaWlpeu6552S32zV27FgdPnxYixcv1vz58yVJL730ku644w5lZWXJbrdrzJgx+s53vqPy8vJQPdOmTQv9PHr0aOXl5Wno0KF67733NHHixHPOW1paqkcffTSSywMAAP1YRI+fysvLdfz4cY0ZM0YOh0MOh0MbN27U0qVL5XA4Qo+UzuTxeDRixIiw3pRRo0apurpaLS0tkqShQ4dq48aNamhoUFVVlbZt26bW1lZdfvnl523L5ZdfrksuuUR79+5t9/O5c+eqrq4utFVVVUVyqQAAoJ+JqKdm4sSJ2rFjR9i+GTNmaOTIkZozZ067j4HGjx+vV199VYFAQDZbMEPt3r1bHo9HMTExYWUTEhKUkJCgkydPat26dXryySfP25ZDhw7p008/lcfjafdzl8vF21EAAHyBRNRTk5iYqNzc3LAtISFBqampys3NlSRNnz5dc+fODR0zc+ZM1dTUqKSkRLt379bbb7+thQsXqri4OFRm3bp1Wrt2rfbv36/169frq1/9qkaOHKkZM2ZICr5t9cADD+iDDz7QgQMHtGHDBk2ZMkXDhg3T5MmTu+M+AACAfq7T89ScT2VlZahHRpKys7O1bt06zZ49W3l5ecrKylJJSYnmzJkTKlNXV6e5c+fq0KFDSklJ0c0336zHH3889Aq43W7Xhx9+qBdffFG1tbXKzMzUDTfcoMcee4zeGAAAIEkyTNM0o92I3uD1euV2u1VXV6ekpKRoNwcAAHRAJN/frP0EAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsoUuhZtGiRTIMQ7NmzbpgudraWhUXF8vj8cjlcmnEiBFas2ZN6PP6+nrNmjVLgwcPVlxcnK699lqVlZWF1WGaph5++GF5PB7FxcWpoKBAe/bs6UrzAQCAhXQ61JSVlWn58uXKy8u7YLmWlhZNmjRJBw4c0BtvvKFdu3ZpxYoVysrKCpW56667tH79er300kvasWOHbrjhBhUUFOjw4cOhMk8++aSWLl2qZcuWaevWrUpISNDkyZPV3Nzc2UsAAAAWYpimaUZ6UENDg8aMGaNf/vKXWrBgga666iotWbKk3bLLli3T4sWL9dFHH8npdJ7z+alTp5SYmKjf/OY3KiwsDO0fO3asbrrpJi1YsECmaSozM1P/8i//on/913+VJNXV1Sk9PV3/+Z//qWnTpl20zV6vV263W3V1dUpKSor0kgEAQBRE8v3dqZ6a4uJiFRYWqqCg4KJlV69erfz8fBUXFys9PV25ublauHCh/H6/JKmtrU1+v1+xsbFhx8XFxWnTpk2SpP3796u6ujrsfG63W+PGjdOWLVvaPa/P55PX6w3bAACAdUUcalatWqXt27ertLS0Q+X37dunN954Q36/X2vWrNG8efP0s5/9TAsWLJAkJSYmKj8/X4899piOHDkiv9+vl19+WVu2bNHRo0clSdXV1ZKk9PT0sLrT09NDn52ttLRUbrc7tGVnZ0d6qQAAoB+JKNRUVVWppKREr7zyyjk9K+cTCASUlpam5557TmPHjtW3v/1t/du//ZuWLVsWKvPSSy/JNE1lZWXJ5XJp6dKl+s53viObrfPjmOfOnau6urrQVlVV1em6AABA3xdRaigvL9fx48c1ZswYORwOORwObdy4UUuXLpXD4Qg9UjqTx+PRiBEjZLfbQ/tGjRql6upqtbS0SJKGDh2qjRs3qqGhQVVVVdq2bZtaW1t1+eWXS5IyMjIkSceOHQur+9ixY6HPzuZyuZSUlBS2AQAA64oo1EycOFE7duxQRUVFaLv66qtVVFSkioqKsOBy2vjx47V3714FAoHQvt27d8vj8SgmJiasbEJCgjwej06ePKl169ZpypQpkqScnBxlZGRow4YNobJer1dbt25Vfn5+RBcMAACsyRFJ4cTEROXm5obtS0hIUGpqamj/9OnTlZWVFRpzM3PmTD3zzDMqKSnRfffdpz179mjhwoW6//77Q3WsW7dOpmnqiiuu0N69e/XAAw9o5MiRmjFjhiSF5sJZsGCBhg8frpycHM2bN0+ZmZmaOnVqV64fAABYREShpiMqKyvDxsJkZ2dr3bp1mj17tvLy8pSVlaWSkhLNmTMnVKaurk5z587VoUOHlJKSoptvvlmPP/542CvgDz74oBobG3X33XertrZWEyZM0Nq1azs8tgcAAFhbp+ap6Y+YpwYAgP6nx+epAQAA6GsINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBIINQAAwBK6FGoWLVokwzA0a9asC5arra1VcXGxPB6PXC6XRowYoTVr1oQ+9/v9mjdvnnJychQXF6ehQ4fqsccek2maoTK33367DMMI22688cauNB8AAFiIo7MHlpWVafny5crLy7tguZaWFk2aNElpaWl64403lJWVpYMHDyo5OTlU5oknntCzzz6rF198UVdeeaX++Mc/asaMGXK73br//vtD5W688Ua98MILod9dLldnmw8AACymU6GmoaFBRUVFWrFihRYsWHDBss8//7xqamq0efNmOZ1OSdKQIUPCymzevFlTpkxRYWFh6PPXXntN27ZtCyvncrmUkZHRmSYDAACL69Tjp+LiYhUWFqqgoOCiZVevXq38/HwVFxcrPT1dubm5Wrhwofx+f6jMtddeqw0bNmj37t2SpD//+c/atGmTbrrpprC63nvvPaWlpemKK67QzJkz9emnn573vD6fT16vN2wDAADWFXFPzapVq7R9+3aVlZV1qPy+ffv07rvvqqioSGvWrNHevXt17733qrW1VfPnz5ckPfTQQ/J6vRo5cqTsdrv8fr8ef/xxFRUVheq58cYb9c1vflM5OTn6+OOP9eMf/1g33XSTtmzZIrvdfs55S0tL9eijj0Z6eQAAoJ8yzDNH415EVVWVrr76aq1fvz40lub666/XVVddpSVLlrR7zIgRI9Tc3Kz9+/eHwsdTTz2lxYsX6+jRo5KCQemBBx7Q4sWLdeWVV6qiokKzZs3SU089pdtuu63devft26ehQ4fqnXfe0cSJE8/53OfzyefzhX73er3Kzs5WXV2dkpKSOnrJAAAgirxer9xud4e+vyPqqSkvL9fx48c1ZsyY0D6/36/3339fzzzzjHw+3zm9Jh6PR06nM2z/qFGjVF1drZaWFsXExOiBBx7QQw89pGnTpkmSRo8erYMHD6q0tPS8oebyyy/XJZdcor1797YbalwuFwOJAQD4Aoko1EycOFE7duwI2zdjxgyNHDlSc+bMafcx0Pjx4/Xqq68qEAjIZgsO4dm9e7c8Ho9iYmIkSU1NTaHPTrPb7QoEAudty6FDh/Tpp5/K4/FEcgkAAMCiIhoonJiYqNzc3LAtISFBqampys3NlSRNnz5dc+fODR0zc+ZM1dTUqKSkRLt379bbb7+thQsXqri4OFTm61//uh5//HG9/fbbOnDggH7961/rqaee0j/90z9JCr5t9cADD+iDDz7QgQMHtGHDBk2ZMkXDhg3T5MmTu+M+AACAfq7T89ScT2VlZVivS3Z2ttatW6fZs2crLy9PWVlZKikp0Zw5c0JlfvGLX2jevHm69957dfz4cWVmZuqee+7Rww8/LCnYa/Phhx/qxRdfVG1trTIzM3XDDTfoscce4xETAACQFOFA4f4skoFGAACgb4jk+5u1nwAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCUQagAAgCV0KdQsWrRIhmFo1qxZFyxXW1ur4uJieTweuVwujRgxQmvWrAl97vf7NW/ePOXk5CguLk5Dhw7VY489JtM0Q2VM09TDDz8sj8ejuLg4FRQUaM+ePV1pPgAAsBBHZw8sKyvT8uXLlZeXd8FyLS0tmjRpktLS0vTGG28oKytLBw8eVHJycqjME088oWeffVYvvviirrzySv3xj3/UjBkz5Ha7df/990uSnnzySS1dulQvvviicnJyNG/ePE2ePFl//etfFRsb29nLAAAAFtGpUNPQ0KCioiKtWLFCCxYsuGDZ559/XjU1Ndq8ebOcTqckaciQIWFlNm/erClTpqiwsDD0+WuvvaZt27ZJCvbSLFmyRD/5yU80ZcoUSdKvfvUrpaen66233tK0adM6cxkAAMBCOvX4qbi4WIWFhSooKLho2dWrVys/P1/FxcVKT09Xbm6uFi5cKL/fHypz7bXXasOGDdq9e7ck6c9//rM2bdqkm266SZK0f/9+VVdXh53P7XZr3Lhx2rJlS7vn9fl88nq9YRsAALCuiHtqVq1ape3bt6usrKxD5fft26d3331XRUVFWrNmjfbu3at7771Xra2tmj9/viTpoYcektfr1ciRI2W32+X3+/X444+rqKhIklRdXS1JSk9PD6s7PT099NnZSktL9eijj0Z6eQAAoJ+KKNRUVVWppKRE69ev7/A4lkAgoLS0ND333HOy2+0aO3asDh8+rMWLF4dCzX/913/plVde0auvvqorr7xSFRUVmjVrljIzM3XbbbdFflWS5s6dqx/96Eeh371er7KzsztVFwAA6PsiCjXl5eU6fvy4xowZE9rn9/v1/vvv65lnnpHP55Pdbg87xuPxyOl0hu0fNWqUqqur1dLSopiYGD3wwAN66KGHQmNjRo8erYMHD6q0tFS33XabMjIyJEnHjh2Tx+MJ1XPs2DFdddVV7bbV5XLJ5XJFcnkAAKAfi2hMzcSJE7Vjxw5VVFSEtquvvlpFRUWqqKg4J9BI0vjx47V3714FAoHQvt27d8vj8SgmJkaS1NTUJJstvCl2uz10TE5OjjIyMrRhw4bQ516vV1u3blV+fn4klwAAACwqop6axMRE5ebmhu1LSEhQampqaP/06dOVlZWl0tJSSdLMmTP1zDPPqKSkRPfdd5/27NmjhQsXhl7VlqSvf/3revzxx3XZZZfpyiuv1J/+9Cc99dRTuuOOOyQpNBfOggULNHz48NAr3ZmZmZo6dWpXrh8AAFhEp+epOZ/KysqwXpfs7GytW7dOs2fPVl5enrKyslRSUqI5c+aEyvziF7/QvHnzdO+99+r48ePKzMzUPffco4cffjhU5sEHH1RjY6Puvvtu1dbWasKECVq7di1z1AAAAEmSYZ45ba+Feb1eud1u1dXVKSkpKdrNAQAAHRDJ9zdrPwEAAEsg1AAA0Bc1e6WTB4J/Xmj/+cp9AXX7mBoAANAJzV7pVI0UlyLV7JPK/1OqOyQ546Urp0jZX5aqP5R2r5NaGqWYBMl9mXT8L5KvXrLHSGNuk0ZM+ry+2srgz8mXSbFJF95/sXa1+qSmTyRHnNR2ShqYI7mzeuRWdBahBgCAaDtSIVW8Kp06GQwrJw9IJ/ZIzbVS6ylpzzop/hIp0CrZnNKgEdL+P0hNJyRTkiHJMKQDf5Cu/7F02Tjpf38eDEGSlJEnjS8JhqE//Ew6sVsy7NKgK4L7h4w/t03NXmnPemnXGunTj6WT+yUzILX5pJgBUqJHmlAi5X2r127TxTBQGACAaGr2Su8ukBpPBHs+qv8qHd4mBfzBQKPAGYUNSTbJZkgBU5L/rMoMyTVAyhon1eyR/G2S3SnZ7NIlw6VjOyXv0WA4sdmDASl5iPSPP/s82JwOM+UvSkf/JPl9UluLgunpMzan5BwgJaRI016T0q7osdsTyfc3PTUAAETTqZpgD407K/ioyTVAam2WAm0KDzRSMFiYwcDTLlPyNQR7bBQIFrcZkjNBqioL9vyYnx0baPvs/J9Km38hNZ2UPt0r7f2ddPTPwUBlmu20QcEeI99JyVcr/eY+KfebUtaXpLRRF3+c1YMINQAARFNcihQ3UKo7HBwbU7klGBp0vgcp7YSMMKYU8H3+q1+Sv0XBd4POOjbQJjV+Ku19J/iIy7xY3e2c63CZdOSPwR6hjL+X/u+TUuZVEdbTPXj7CQCAaIpNkq76ruSMlSo3Bwfh6txlh7rufIHFHwxREQeaM+o1/VJbs3Roq7T6/qi9iUWoAQAg2jKvkobfEAwW9lhdvDemDzv2F+lQeVROTagBAKAvSPRINkdwYG5/DjUKSPVHo3JmQg0AAH1BoE1yxH82nqY/swVfFY/OmQEAQFQ1e6Wy/1D0e2i6IRa4EqXG412vpxMINQAARFttZXCiPMOmqH0125w6/xtXEdq9LiqDhQk1AAD0BWZAamn6LNhEwQVfI4+wnsZPgnPv9DJCDQAA0ZZ8mZQ6XJI/ON9LtDgSul5Hqy+4ZEPcwK7XFSFCDQAA0RabFFyDyeX+bJ6aaOmGMT1mQMq9JSozCxNqAADoCwYO+XzpgmjpjkDliJFSh3W9nk4g1AAA0Bf87X+Ci1r2iEgGIBtdO5XpD64GHgWs/QQAQLQ1e6V9G9Vzr3RHUm9XBwt3MRR1AT01AABE26kaqalGlvhadiVKMd0w4LgTLHD3AADo52xOqflkL3Vy9PBJBqRLydk9e47zINQAABBtgVYpYdBni1n2NFMyenD0SXO95KvvufovgFADAEC0xaVIlwyX4lMkW0zPn8/sqbE7htRSL9Ue7KH6L4xQAwBAtMUmSWNv76VXoY0uzFp8sUdXZvDNJ7urk/V3DaEGAIC+YM966fAfpUBLD5/IDL523dljL8YZK/l9nay/awg1AABE2/Fd0pZ/7935XXrqMdeANCl5cM/UfRGEGgAAou3YDqm1Sb03x4vx2QKW3V2tTRpxo+TO6v66O4BQAwBAtKWP/mwcSnsDeHsi6ATULStyn820S5/sCk4mGAWEGgAAoi3tCmncPWe9am1I9pjP3oiK4srdEWmVPv69VPYfUTk7oQYAgL5g/P1S+pX6/KvZDC5w2VwfwaOi6C1REGK2SeW/kuoO9/qpCTUAAPQFtZVSc51k2IObFJxPJqK3oXrgkVJntHijMlcNoQYAgD7DlOyOLswj00f4W6W41F4/bT+/awAAWETyZcF1k/wt3fxmUhQeSSV6gvPV9DJCDQAAfcFffi0d+8tZE+PZz+i16cRXthGlAcapw6S4gb1+WkINAADRVndY+t+fS23NnwWR070r/s+GyRhq/3XvCzl9TG+Ps7FJWVcHl37o/TN33qJFi2QYhmbNmnXBcrW1tSouLpbH45HL5dKIESO0Zs2a0OdDhgyRYRjnbMXFxaEy119//Tmf/+AHP+hK8wEA6BtO7g/OJmzYJbv9rFe4DUn2yOsckB6dsTk2m3RoW1Tmqun02uNlZWVavny58vLyLliupaVFkyZNUlpamt544w1lZWXp4MGDSk5ODqvL7/+8u23nzp2aNGmSbrnllrC6vv/97+unP/1p6Pf4+PjONh8AgL5jYE7wcU1znRTwn/UIqiPrNBkK75ExpIbq7m1jh9ml43+VaqukjCt79cydCjUNDQ0qKirSihUrtGDBgguWff7551VTU6PNmzfL6QwmzyFDhoSVGTRoUNjvixYt0tChQ3XdddeF7Y+Pj1dGRkZnmgwAQN/lzpL+z4+k90ol71HJH9C5QaWjTvfqdHbRyq7yK1rz5XSqX6q4uFiFhYUqKCi4aNnVq1crPz9fxcXFSk9PV25urhYuXBjWM3OmlpYWvfzyy7rjjjtkGOE35ZVXXtEll1yi3NxczZ07V01NTZ1pPgAAfU/et6R//LmUcrnkGnDGo6OOBIQzwo9hV/QCzWfnHzRSSs7u9VNH3FOzatUqbd++XWVlZR0qv2/fPr377rsqKirSmjVrtHfvXt17771qbW3V/Pnzzyn/1ltvqba2VrfffnvY/u9+97saPHiwMjMz9eGHH2rOnDnatWuX3nzzzXbP6/P55PN9vvS51xuddSgAAOiQD/9Lem+RdPKAJCMYaky/Otxb44iT2k5JZiST9fUAR6z0D3dFZaBwRKGmqqpKJSUlWr9+vWJjO/b+eSAQUFpamp577jnZ7XaNHTtWhw8f1uLFi9sNNStXrtRNN92kzMzMsP1333136OfRo0fL4/Fo4sSJ+vjjjzV06NBz6iktLdWjjz4ayeUBABAddYelTT+XfF5JRjDMhA2R+WzwsN+n84acQFtwUUy/r/3Pe4UhOVzBpRKiIKLHT+Xl5Tp+/LjGjBkjh8Mhh8OhjRs3aunSpXI4HO0+UvJ4PBoxYoTs9s9Hbo8aNUrV1dVqaQlPkwcPHtQ777yju+6666JtGTdunCRp79697X4+d+5c1dXVhbaqqqpILhUAgN5zcr/UdEJqazmjd+Z0eDEU/Lq26YK9NoHWKAcaSTIlX4P0p1f6/ttPEydO1I4dO8L2zZgxQyNHjtScOXPCgstp48eP16uvvqpAICCbLZihdu/eLY/Ho5iYmLCyL7zwgtLS0lRYWHjRtlRUVEgKhqb2uFwuuVyujlwWAADRFT9IavNJLQ0KHyBsSLEDpeaa4NID/YG/JfhKdxTefoqopyYxMVG5ublhW0JCglJTU5WbmytJmj59uubOnRs6ZubMmaqpqVFJSYl2796tt99+WwsXLgybg0YKPqZ64YUXdNttt8nhCM9aH3/8sR577DGVl5frwIEDWr16taZPn66vfOUrF32lHACAPs/pkpIHS8bZk+yZUvPJaLWqE2zBRTibTkoNx3v97J2ep+Z8KisrQz0ykpSdna1169Zp9uzZysvLU1ZWlkpKSjRnzpyw49555x1VVlbqjjvuOKfOmJgYvfPOO1qyZIkaGxuVnZ2tm2++WT/5yU+6u/kAAPS+uBQpySNVf9jOh31k5e2OMGzBzeYIzrfT26c3TbMf3a3O83q9crvdqqurU1JS74/IBgDgvJq90n/dLu37vSJfDqEPMRySPUZKypBu+21w/p0uiuT7m7WfAACItlM1wT9tUfxaNjqxFMM5dSjY43T93G4JNJHq9sdPAAAgQnEpUvxARWsmXknBsTCdZguGIkes9I9LpMu/0l2tirQVAAAgqmKTpLxpwTleoqYLgcqwSTHxkjNeskevv4RQAwBAXzBouJSeKxnOi5ftEV0YYmu2Sb764IzGvsbua1KECDUAAPQFcSlS6lDJ2bEZ+7tfF98bsn32+GnX21GZeE8i1AAA0DfEJkmjvh5czNLWk49wzveY6fSsxZ14DGWPlS4ZKcUlB+enORWduXUINQAA9BWDx0tDvyYlpEvOhODgW8Ouz5dKsJ+xeveFnB1MPnuzyREbDCDnFLdLiZnBCQCd8e2Xudg5WuqDc9MMSJPiBnbg+O7H208AAPQVsUnSNXdLraeCSw2cqpVMM5gfHHFSzIDgZ47YYHCo2SO1nFLY3Db22M/CkCS7Mxg0/K2SHNIlI4I/13ws+f3BGYxNf3AhzMvGBT9zuKTLvixtekryHm6nkQ5J/vBwZXcGf/f8vTT29qis0H26ZQAAoK/IvEr6+s+Daye1fDbotu6QdOD9YMhxxklfulWKSZD+8P+kQ3+UTtVJCgTDTHyKlPkl6bJ86cRuqfGTYHgZPEGq2Rfc/L7gWlOGTUrMCG42u5RwiXTVd4NtSBslrflX6ZNdny2yaZNShwXnn/nkI6m5LviYzHOVNHaGNOgKKTk7aoFGYkZhAAD6h2ZvcKxK3MDPg0OzNzz8SMGwczpcnH3M6d9tjmBAkoJlpXPrPl3/oXLJe1RKuyIYeuIGBt90Ova3YNm0kT0aZCL5/ibUAACAPotlEgAAwBcOoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFgCoQYAAFhCl0LNokWLZBiGZs2adcFytbW1Ki4ulsfjkcvl0ogRI7RmzZrQ50OGDJFhGOdsxcXFoTLNzc0qLi5WamqqBgwYoJtvvlnHjh3rSvMBAICFODp7YFlZmZYvX668vLwLlmtpadGkSZOUlpamN954Q1lZWTp48KCSk5PD6vL7/aHfd+7cqUmTJumWW24J7Zs9e7befvttvf7663K73frhD3+ob37zm/rf//3fzl4CAACwkE6FmoaGBhUVFWnFihVasGDBBcs+//zzqqmp0ebNm+V0OiUFe2bONGjQoLDfFy1apKFDh+q6666TJNXV1WnlypV69dVX9bWvfU2S9MILL2jUqFH64IMP9OUvf7kzlwEAACykU4+fiouLVVhYqIKCgouWXb16tfLz81VcXKz09HTl5uZq4cKFYT0zZ2ppadHLL7+sO+64Q4ZhSJLKy8vV2toadr6RI0fqsssu05YtW9qtx+fzyev1hm0AAMC6Iu6pWbVqlbZv366ysrIOld+3b5/effddFRUVac2aNdq7d6/uvfdetba2av78+eeUf+utt1RbW6vbb789tK+6uloxMTFhj6wkKT09XdXV1e2et7S0VI8++miHrwsAAPRvEfXUVFVVqaSkRK+88opiY2M7dEwgEFBaWpqee+45jR07Vt/+9rf1b//2b1q2bFm75VeuXKmbbrpJmZmZkTTtHHPnzlVdXV1oq6qq6lJ9AACgb4uop6a8vFzHjx/XmDFjQvv8fr/ef/99PfPMM/L5fLLb7WHHeDweOZ3OsP2jRo1SdXW1WlpaFBMTE9p/8OBBvfPOO3rzzTfD6sjIyFBLS4tqa2vDemuOHTumjIyMdtvqcrnkcrkiuTwAANCPRdRTM3HiRO3YsUMVFRWh7eqrr1ZRUZEqKirOCTSSNH78eO3du1eBQCC0b/fu3fJ4PGGBRgoO/k1LS1NhYWHY/rFjx8rpdGrDhg2hfbt27VJlZaXy8/MjuQQAAGBREfXUJCYmKjc3N2xfQkKCUlNTQ/unT5+urKwslZaWSpJmzpypZ555RiUlJbrvvvu0Z88eLVy4UPfff39YPYFAQC+88IJuu+02ORzhzXK73brzzjv1ox/9SCkpKUpKStJ9992n/Px83nwCAACSujBPzflUVlbKZvu8Ayg7O1vr1q3T7NmzlZeXp6ysLJWUlGjOnDlhx73zzjuqrKzUHXfc0W69Tz/9tGw2m26++Wb5fD5NnjxZv/zlL7u7+QAAoJ8yTNM0o92I3uD1euV2u1VXV6ekpKRoNwcAAHRAJN/frP0EAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsgVADAAAsodtnFO6rTs8x6PV6o9wSAADQUae/tzsyV/AXJtTU19dLCi7bAAAA+pf6+nq53e4LlvnCLJMQCAR05MgRJSYmyjCMaDenw7xer7Kzs1VVVcXyDr2I+977uOfRwX3vfdzzyJimqfr6emVmZoatLdmeL0xPjc1m06WXXhrtZnRaUlIS//ijgPve+7jn0cF9733c8467WA/NaQwUBgAAlkCoAQAAlkCo6eNcLpfmz58vl8sV7aZ8oXDfex/3PDq4772Pe95zvjADhQEAgLXRUwMAACyBUAMAACyBUAMAACyBUAMAACyBUBNFixYtkmEYmjVr1nnLXH/99TIM45ytsLAwVMY0TT388MPyeDyKi4tTQUGB9uzZ0wtX0P901z1/8803dcMNNyg1NVWGYaiioqLnG9+Pdcd9b21t1Zw5czR69GglJCQoMzNT06dP15EjR3rpKvqX7vq3/sgjj2jkyJFKSEjQwIEDVVBQoK1bt/bCFfRP3XXfz/SDH/xAhmFoyZIlPdNoCyHURElZWZmWL1+uvLy8C5Z78803dfTo0dC2c+dO2e123XLLLaEyTz75pJYuXaply5Zp69atSkhI0OTJk9Xc3NzTl9GvdOc9b2xs1IQJE/TEE0/0dLP7ve66701NTdq+fbvmzZun7du3680339SuXbv0jW98ozcuo1/pzn/rI0aM0DPPPKMdO3Zo06ZNGjJkiG644QZ98sknPX0Z/U533vfTfv3rX+uDDz5QZmZmTzXbWkz0uvr6enP48OHm+vXrzeuuu84sKSnp8LFPP/20mZiYaDY0NJimaZqBQMDMyMgwFy9eHCpTW1trulwu87XXXuvupvdb3XnPz7R//35TkvmnP/2p+xprIT1130/btm2bKck8ePBgN7TWGnr6ntfV1ZmSzHfeeacbWmsdPXHfDx06ZGZlZZk7d+40Bw8ebD799NPd22gLoqcmCoqLi1VYWKiCgoKIj125cqWmTZumhIQESdL+/ftVXV0dVpfb7da4ceO0ZcuWbmtzf9ed9xwd19P3va6uToZhKDk5uQuttJaevOctLS167rnn5Ha79fd///ddbaqldPd9DwQC+t73vqcHHnhAV155ZXc21dK+MAta9hWrVq3S9u3bVVZWFvGx27Zt086dO7Vy5crQvurqaklSenp6WNn09PTQZ1903X3P0TE9fd+bm5s1Z84cfec732FRwM/01D3/7W9/q2nTpqmpqUkej0fr16/XJZdc0h1NtoSeuO9PPPGEHA6H7r///u5q5hcCoaYXVVVVqaSkROvXr1dsbGzEx69cuVKjR4/WNddc0wOtsybueXT09H1vbW3Vt771LZmmqWeffbarzbWEnrznX/3qV1VRUaETJ05oxYoV+ta3vqWtW7cqLS2tO5rer/XEfS8vL9fPf/5zbd++XYZhdGdzrS/az7++SH7961+bkky73R7aJJmGYZh2u91sa2s777ENDQ1mUlKSuWTJkrD9H3/8cbtjOr7yla+Y999/f09cRr/SE/f8TIypaV9P3veWlhZz6tSpZl5ennnixImeuoR+p6f/rZ9p2LBh5sKFC7ur6f1aT9z3p59+OnT8mXXabDZz8ODBPXxF/Rs9Nb1o4sSJ2rFjR9i+GTNmaOTIkZozZ47sdvt5j3399dfl8/l06623hu3PyclRRkaGNmzYoKuuukqS5PV6tXXrVs2cObPbr6G/6Yl7jovrqft+uodmz549+v3vf6/U1NRub3t/1Zv/1gOBgHw+X5faaxU9cd+/973vnTM2Z/Lkyfre976nGTNmdF/jLYhQ04sSExOVm5sbti8hIUGpqamh/dOnT1dWVpZKS0vDyq1cuVJTp0495z/ip+dDWLBggYYPH66cnBzNmzdPmZmZmjp1ao9eT3/QE/dckmpqalRZWRmaI2XXrl2SpIyMDGVkZPTEpfQrPXHfW1tb9c///M/avn27fvvb38rv94fGjaWkpCgmJqYHr6jv64l73tjYqMcff1zf+MY35PF4dOLECf37v/+7Dh8+3O7rx19EPXHfU1NTz9nndDqVkZGhK664ogeuwjoINX1MZWWlbLbwl9J27dqlTZs26Xe/+127xzz44INqbGzU3XffrdraWk2YMEFr167t1PPdL6LO3PPVq1eH/R/TtGnTJEnz58/XI4880mNttZJI7/vhw4e1evVqSQr1Sp72+9//Xtdff31PNdUyIr3ndrtdH330kV588UWdOHFCqamp+od/+Af94Q9/4I2cCHTmvzHoHMM0TTPajQAAAOgq5qkBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACWQKgBAACW8P8BcZXrsZEog4IAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 6\n",
    "device = torch.device(\"cpu\")\n",
    "net.to(device)\n",
    "lowerCoordinate = torch.Tensor([4.6975, 4.6975, 2.9975, 0.9499, -0.0001, -0.0001]).to(device)\n",
    "upperCoordinate = torch.Tensor([4.7025, 4.7025 ,3.0025, 0.9501,  0.0001,  0.0001 ]).to(device)\n",
    "inputData = (upperCoordinate - lowerCoordinate) * torch.rand(1000, dim, device=device) \\\n",
    "                                                        + lowerCoordinate\n",
    "plt.scatter(inputData[:, 0], inputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "outputData = net(inputData).detach().cpu().numpy()\n",
    "plt.scatter(outputData[:, 0], outputData[:, 1], marker='.', label='Initial', alpha=0.5)\n",
    "plt.axis(\"equal\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "lastDim = 6\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(6, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, lastDim))\n",
    "\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(\"tempBestStateDict.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "trainCompleteLoop = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "print(\"best loss: \", bestLoss)\n",
    "net.load_state_dict(bestStateDic)\n",
    "layers = []\n",
    "dimensions = [net[0].weight.shape[1]]\n",
    "# for i in range(len(net)):\n",
    "#     if i % 2 == 0:\n",
    "#         dimensions.append(net[i].weight.shape[0])\n",
    "# for i in range(len(dimensions) - 1):\n",
    "#     layers.append(nn.Linear(dimensions[i], dimensions[i + 1]))\n",
    "#     if i < len(dimensions) - 2:\n",
    "#         layers.append(nn.ReLU())\n",
    "# network = nn.Sequential(*layers)\n",
    "networkClass = NeuralNetwork(\"../randomNetwork.pth\")\n",
    "\n",
    "networkClass.Linear = net\n",
    "if trainCompleteLoop:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorFullLoopV1.1.pth\")\n",
    "else:\n",
    "    torch.save(networkClass.state_dict(), \"../quadRotorNormalV1.1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(trainLosses)\n",
    "plt.plot([validationLoss.item() for validationLoss in validationLosses])\n",
    "plt.legend([\"train loss\", \"validation loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "7"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11457, 6)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}